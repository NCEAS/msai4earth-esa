{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbda4e9d-2ab4-466f-a368-5e9fc7431ee2",
   "metadata": {},
   "source": [
    "# Feral Pigs in CA\n",
    "- Search the latest GBIF snapshot in the Planetary Computer for pig (*Sus scroga*) sightings in California, US. \n",
    "- Plot a map with the occurrences \n",
    "- Count how many records there are per year\n",
    "- Check if any pigs were recorded in Sedgwick's reserve bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601c46e5-2369-4d0f-9e4c-268dd555d326",
   "metadata": {},
   "source": [
    "More info on GBIF dataset:\n",
    "\n",
    "https://github.com/microsoft/AIforEarthDataSets/blob/main/data/gbif.md\n",
    "\n",
    "https://data-blog.gbif.org/post/gbif-filtering-guide/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f0b2a3-6a8f-4f59-ad10-962e0acacc66",
   "metadata": {},
   "source": [
    "NOTE: the libraries are imported as needed to make it explicit where they are used. The libraries used in the notebook are:\n",
    "\n",
    "`pystac_client`\n",
    "`planetary_computer`\n",
    "`dask.dataframe`\n",
    "`dask_gateway`\n",
    "\n",
    "`geopandas`\n",
    "`matplotlib.pyplot`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f9c54-7b24-47aa-9372-ec2586b0cc34",
   "metadata": {},
   "source": [
    "\n",
    "## Acessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe1c814e-348e-475f-be43-16eea53e928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac_client # access STAC catalogs\n",
    "import planetary_computer # sign items\n",
    "import dask.dataframe as dd # dataframe optimized for parallel computing\n",
    "\n",
    "# ----- accesing Azure storage using pystac client\n",
    "URL = \"https://planetarycomputer.microsoft.com/api/stac/v1\"\n",
    "catalog = pystac_client.Client.open(URL)\n",
    "\n",
    "\n",
    "# ----- access items in gbif catalog\n",
    "search = catalog.search(collections=[\"gbif\"])\n",
    "items = search.get_all_items()\n",
    "items = {x.id: x for x in items}\n",
    "#list(items)\n",
    "\n",
    "\n",
    "# ---- select and sign first item\n",
    "# The snapshot includes all CC-BY licensed data published through GBIF that have coordinates which passed automated quality checks.\n",
    "item = list(items.values())[0]\n",
    "#print(item) \n",
    "\n",
    "signed_asset = planetary_computer.sign(item).assets[\"data\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb5d294-596d-46ee-b27b-ae5b0db701c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No files satisfy the `require_extension` criteria (files must end with ('.parq', '.parquet')).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ---- read data frame using parquet, specify columns to be included\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msigned_asset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhref\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfamily\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspecies\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstateprovince\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meventdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmonth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mday\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecimallatitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecimallongitude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstitutioncode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msigned_asset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_fields\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtable:storage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#???\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py:326\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, columns, filters, categories, index, storage_options, engine, gather_statistics, ignore_metadata_file, metadata_task_size, split_row_groups, chunksize, aggregate_files, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_parquet options require gather_statistics=True\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    324\u001b[0m     gather_statistics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m read_metadata_result \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgather_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgather_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_row_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_row_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43maggregate_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maggregate_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_metadata_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_metadata_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_task_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_task_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# In the future, we may want to give the engine the\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# option to return a dedicated element for `common_kwargs`.\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;66;03m# However, to avoid breaking the API, we just embed this\u001b[39;00m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# data in the first element of `parts` for now.\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# The logic below is inteded to handle backward and forward\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# compatibility with a user-defined engine.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m meta, statistics, parts, index \u001b[38;5;241m=\u001b[39m read_metadata_result[:\u001b[38;5;241m4\u001b[39m]\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/dask/dataframe/io/parquet/arrow.py:319\u001b[0m, in \u001b[0;36mArrowDatasetEngine.read_metadata\u001b[0;34m(cls, fs, paths, categories, index, gather_statistics, filters, split_row_groups, chunksize, aggregate_files, ignore_metadata_file, metadata_task_size, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_metadata\u001b[39m(\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    317\u001b[0m \n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# Stage 1: Collect general dataset information\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m     dataset_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect_dataset_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgather_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_row_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43maggregate_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_metadata_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata_task_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;66;03m# Stage 2: Generate output `meta`\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_create_dd_meta(dataset_info)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.8/site-packages/dask/dataframe/io/parquet/arrow.py:816\u001b[0m, in \u001b[0;36mArrowDatasetEngine._collect_dataset_info\u001b[0;34m(cls, paths, fs, categories, index, gather_statistics, filters, split_row_groups, chunksize, aggregate_files, ignore_metadata_file, metadata_task_size, require_extension, **dataset_kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m         paths \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    813\u001b[0m             path \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mfind(paths) \u001b[38;5;28;01mif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mendswith(require_extension)\n\u001b[1;32m    814\u001b[0m         ]\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m len0 \u001b[38;5;129;01mand\u001b[39;00m paths \u001b[38;5;241m==\u001b[39m []:\n\u001b[0;32m--> 816\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    817\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files satisfy the `require_extension` criteria \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    818\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(files must end with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequire_extension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    819\u001b[0m             )\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(paths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    822\u001b[0m     paths, base, fns \u001b[38;5;241m=\u001b[39m _sort_and_analyze_paths(paths, fs)\n",
      "\u001b[0;31mValueError\u001b[0m: No files satisfy the `require_extension` criteria (files must end with ('.parq', '.parquet'))."
     ]
    }
   ],
   "source": [
    "# ---- read data frame using parquet, specify columns to be included\n",
    "\n",
    "df = dd.read_parquet(\n",
    "    signed_asset.href,\n",
    "    columns=[\"family\",\n",
    "            \"genus\",\n",
    "            \"class\",\n",
    "            \"species\",\n",
    "            \"stateprovince\",\n",
    "            \"eventdate\",\n",
    "            \"year\",\n",
    "            \"month\",\n",
    "            \"day\",\n",
    "            \"decimallatitude\",\n",
    "            \"decimallongitude\",\n",
    "            \"institutioncode\"],\n",
    "    storage_options=signed_asset.extra_fields[\"table:storage_options\"],  #???\n",
    ")\n",
    "#df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae2cf6-4d4a-4f98-a841-e9a74a0a65bd",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13582c36-1a15-44f0-96f5-68b4517f6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- initialize dask cluster ---\n",
    "from dask_gateway import GatewayCluster\n",
    "\n",
    "cluster = GatewayCluster()\n",
    "cluster.scale(16)\n",
    "client = cluster.get_client()\n",
    "print(cluster.dashboard_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79404d57-8284-449e-83c8-90780c5b95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_obs = df.loc[df['stateprovince'] == 'California'].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8856eb7-c4a5-431b-8721-06e2a558dfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ca_pigs = ca_obs.loc[ca_obs['species'] == 'Sus scrofa']\n",
    "ca_pigs = ca_obs.loc[ca_obs['genus'] == 'Sus']\n",
    "#ca_pigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b9e77-1c89-4935-ac6d-3ea656eacf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to transform lat long entries into point geometry for plotting\n",
    "\n",
    "import geopandas\n",
    "\n",
    "geo_pigs = geopandas.GeoDataFrame(\n",
    "    ca_pigs, \n",
    "    geometry = geopandas.points_from_xy(x=ca_pigs.decimallongitude, y=ca_pigs.decimallatitude)\n",
    ")\n",
    "#geo_pigs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13829020-072f-4645-81c1-d8861323c4f7",
   "metadata": {},
   "source": [
    "## Map observations\n",
    "\n",
    "CA shapefile source: https://data.ca.gov/dataset/ca-geographic-boundaries/resource/3db1e426-fb51-44f5-82d5-a54d7c6e188b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faadbc3-14da-43f2-bc86-42fe5f7ba299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- OPENING SHAPEFILE ----\n",
    "# the shp (espg 3857) and the point data (epsg 4326) have different crs, so we have to match them\n",
    "\n",
    "CA_path = \"/home/jovyan/Sedgwick_Reserve/CA_geometry/CA_State_TIGER2016.shp\"\n",
    "CA_shp = geopandas.read_file(CA_path)\n",
    "#CA_shp.plot(edgecolor='purple', color='yellow')\n",
    "#CA_shp.crs  # ESPSG: 3857\n",
    "CA_shp = CA_shp.to_crs(4326) # match it to point data crs\n",
    "#CA_shp.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2082f97-00fc-4dbe-a47f-729c691238e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- CREATE MAP ----\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,10))\n",
    "CA_shp.plot(ax=ax, color='lightgray')\n",
    "geo_pigs.plot(ax=ax, alpha=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66464af-c7b2-405c-9e3c-febfc90118e3",
   "metadata": {},
   "source": [
    "## Observations by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae5bbc-38a0-4eec-922b-1c6e03aaa40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- COUNT OBSERVATIONS BY YEAR ----\n",
    "\n",
    "# earliest is on 1818, latest on 2021\n",
    "\n",
    "obs_by_year = ca_pigs.filter(items=['year']).groupby(['year']).size().reset_index(name='count')\n",
    "print(obs_by_year.head(5))\n",
    "print(obs_by_year.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c592ade3-3434-45d1-abac-c4ec886ea8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- HISTOGRAM ----\n",
    "\n",
    "fig, ax = plt.subplots(figsize =(10, 10))\n",
    "ax.hist(ca_pigs.filter(items=['year']), bins = range(1810,2021))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30d41cf-aaff-4d16-89d6-fef4b224310b",
   "metadata": {},
   "source": [
    "## (no) Pigs at Sedgwick\n",
    "\n",
    "Shapefile for Sedgiwck reserve come from UC Natural Reserve System Boundaries.\n",
    "\n",
    "https://nrs-ucanr.opendata.arcgis.com/datasets/UCANR::uc-natural-reserve-system-boundaries/about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da398b2a-5d5c-483f-9469-8b06d6fb66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- OPENING SHAPEFILE ----\n",
    "\n",
    "sedg_shp_path = \"/home/jovyan/Sedgwick_Reserve/sedgwick_geometry/sedgwick_geometry.shp\"\n",
    "sedg_shp = geopandas.read_file(sedg_shp_path)\n",
    "#sedg_shp.plot(edgecolor='purple', color='yellow')\n",
    "\n",
    "# --- matching CRS to data point\n",
    "#print(sedg_shp.crs)\n",
    "sedg_shp = sedg_shp.to_crs(4326)\n",
    "#print(sedg_shp.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3245dfa-97a7-4144-96be-63883935b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- FILTERING DATASET TO SEDGWICK BOUNDING BOX -----\n",
    "\n",
    "#print(sedg_shp.bounds)\n",
    "\n",
    "minx = sedg_shp.bounds['minx'][0]\n",
    "miny = sedg_shp.bounds['miny'][0]\n",
    "maxx = sedg_shp.bounds['maxx'][0]\n",
    "maxy = sedg_shp.bounds['maxy'][0]\n",
    "\n",
    "sedg_pigs = ca_pigs.loc[(miny < ca_pigs['decimallatitude'] ) & (ca_pigs['decimallatitude'] < maxy) &\n",
    "          (minx < ca_pigs['decimallongitude'] ) & (ca_pigs['decimallongitude'] < maxx)]\n",
    "\n",
    "sedg_pigs.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e185a647-5880-464d-ac9d-957aba4f3af5",
   "metadata": {},
   "source": [
    "## iNaturalist records\n",
    "\n",
    "See thread about iNaturalist records on GBIF\n",
    "https://forum.inaturalist.org/t/gbif-connection-to-inaturalist/16822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509dec65-5b0a-45e3-aa86-d8014b43a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- COUNTING OBSERVATIONS BY INSTITUTION ----\n",
    "\n",
    "#ca_pigs['institutioncode'].unique()\n",
    "institutions = ca_pigs.filter(items=['institutioncode']).groupby(['institutioncode']).size().reset_index(name='count')\n",
    "institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b12581-7712-4d71-879c-5185bb6286f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inat_pigs = ca_pigs.loc(ca_pigs['institutioncode']=='iNaturalist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86041c17-44f3-4db2-be37-e32a2e7d5a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
