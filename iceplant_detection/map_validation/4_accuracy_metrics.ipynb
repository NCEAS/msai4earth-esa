{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from skimpy import clean_columns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def ref_class_column(df):\n",
    "\n",
    "#     map_class = df.pl_class\n",
    "#     ref_class = []\n",
    "\n",
    "#     for i in map_class.index:\n",
    "#         if df.category_non_iceplant_vegetation.loc[i] == 100:\n",
    "#             ref_class.append(0)\n",
    "#         elif df.category_iceplant.loc[i] == 100:\n",
    "#             ref_class.append(1)\n",
    "#         elif df.category_low_ndvi_impervious_surface.loc[i] == 100:\n",
    "#             ref_class.append(2)\n",
    "#         elif df.category_water.loc[i] == 100:\n",
    "#             ref_class.append(3)\n",
    "#         else:\n",
    "#             ref_class[j]= 100\n",
    "            \n",
    "#     return ref_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref_class_column(df, map_col):\n",
    "    ref_class = []\n",
    "\n",
    "    for i in df.index:\n",
    "        if df[map_col].loc[i] == 'non-iceplant vegetation':\n",
    "            ref_class.append(0)\n",
    "            \n",
    "        elif df[map_col].loc[i] == 'iceplant':\n",
    "            ref_class.append(1)\n",
    "            \n",
    "        elif df[map_col].loc[i] == 'low ndvi (impervious surface)':\n",
    "            ref_class.append(2)\n",
    "            \n",
    "        elif df[map_col].loc[i] == 'water':\n",
    "            ref_class.append(3)\n",
    "        else:\n",
    "            print(i)\n",
    "            ref_class.append(100)\n",
    "            \n",
    "    return ref_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> column names have been cleaned\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2\u001b[0m column names have been cleaned\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "year = 2020\n",
    "\n",
    "file_name = 'ceo-AE5FP_2020_model_map_validation-sample-data-2023-02-02.csv'\n",
    "df = clean_columns(pd.read_csv(os.path.join(os.getcwd(),file_name)))\n",
    "\n",
    "file_name = 'modelAE5_FP_2020_rasters_2020_pixel_counts.csv'\n",
    "pix_counts = pd.read_csv(os.path.join(os.getcwd(), file_name))\n",
    "\n",
    "ref_col = 'category'  # ground truth (reference) column \n",
    "map_col = 'pl_class'  # point classification in map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([186])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([236, 139, 119, 100]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_class = ref_class_column(df, ref_col) \n",
    "np.unique(ref_class, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([200, 199, 110,  85]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_class = df[map_col].to_numpy()\n",
    "np.unique(map_class, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[170,   1,  20,   9],\n",
       "       [ 51, 137,  11,   0],\n",
       "       [ 15,   1,  85,   9],\n",
       "       [  0,   0,   3,  82]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "# using confusion_matrix directly we get a matrix C such that\n",
    "# C_{i,j} = known to be i, predicted as  j \n",
    "# The notation in the paper is \n",
    "# n_{i,j} = predicted as i, known to be j \n",
    "# so we need to take the transpose\n",
    "\n",
    "n = confusion_matrix(ref_class, map_class, labels=range(0,4)).T\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_nonice_2020</th>\n",
       "      <th>n_ice_2020</th>\n",
       "      <th>n_ground_2020</th>\n",
       "      <th>n_water_2020</th>\n",
       "      <th>raster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36271293</td>\n",
       "      <td>5382187</td>\n",
       "      <td>111150412</td>\n",
       "      <td>62968690</td>\n",
       "      <td>modelAE5_FP_2020_merged_crs26910_S_2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1122203</td>\n",
       "      <td>30004</td>\n",
       "      <td>1891593</td>\n",
       "      <td>2893071</td>\n",
       "      <td>modelAE5_FP_2020_merged_crs26910_W_2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89669636</td>\n",
       "      <td>1123921</td>\n",
       "      <td>62587031</td>\n",
       "      <td>69125241</td>\n",
       "      <td>modelAE5_FP_2020_merged_crs26911_2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_nonice_2020  n_ice_2020  n_ground_2020  n_water_2020  \\\n",
       "0       36271293     5382187      111150412      62968690   \n",
       "1        1122203       30004        1891593       2893071   \n",
       "2       89669636     1123921       62587031      69125241   \n",
       "\n",
       "                                    raster  \n",
       "0  modelAE5_FP_2020_merged_crs26910_S_2020  \n",
       "1  modelAE5_FP_2020_merged_crs26910_W_2020  \n",
       "2    modelAE5_FP_2020_merged_crs26911_2020  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pix_counts = pd.read_csv(os.path.join(os.getcwd(), 'modelAE5_FP_2020_rasters_2020_pixel_counts.csv'))\n",
    "pix_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_pix = sum([sum(pix_counts.n_nonice_2020),\n",
    "                  sum(pix_counts.n_ice_2020),\n",
    "                  sum(pix_counts.n_ground_2020),\n",
    "                  sum(pix_counts.n_water_2020)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 85.19281389053452\n",
      "overall accuracy conf interval: 3.6243670717266014 \n",
      "\n",
      "users accuracy: [0.85, 0.6884422110552764, 0.7727272727272727, 0.9647058823529412]\n",
      "users accuracies conf interval: [4.9611759  6.45099237 7.86737053 3.94607246]\n"
     ]
    }
   ],
   "source": [
    "W = []      # proportion of area mapped as class i\n",
    "n_idot = [] # pixels in sample that had class i in map (predicted as i, any true class j)\n",
    "U_hat = []  # estimated users' accuracy (precision for each class: TP/(TP+FP))\n",
    "\n",
    "for i in range(0,4):\n",
    "    W.append( sum(pix_counts.iloc[:,i]) / total_pix)\n",
    "    n_idot.append(sum(n[i,:]))\n",
    "    U_hat.append(n[i,i] / n_idot[i])\n",
    "\n",
    "OA = sum([W[i]*n[i,i]/n_idot[i] for i in range(0,4)])\n",
    "print('overall accuracy:', OA*100)\n",
    "\n",
    "var_O = sum([ W[i]**2 * U_hat[i] * (1-U_hat[i])/(n_idot[i]-1) for i in range(0,4)])\n",
    "# std error of estimated overall accuracy -- paper equation (5)\n",
    "print('overall accuracy conf interval:', np.sqrt(var_O)*196, '\\n')\n",
    "\n",
    "print('users accuracy:', U_hat)\n",
    "\n",
    "var_U_hat = [U_hat[i] * (1-U_hat[i])/(n_idot[i]-1) for i in range(0,4)]\n",
    "print('users accuracies conf interval:', 196*np.sqrt(var_U_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producers accuracy: [0.8082402844924153, 0.6684417997754406, 0.8838657732434829, 0.8663598116981505]\n"
     ]
    }
   ],
   "source": [
    "p_dotk_hat = []\n",
    "P_hat = []  # estimated producer's accurace (sensitiviy for each class TP/(TP+FN))\n",
    "\n",
    "for k in range(0,4):\n",
    "    partial = [ W[i]*n[i,k]/n_idot[i] for i in range(0,4) ]\n",
    "    p_dotk_hat.append(sum(partial))  # equation (9)\n",
    "p_dotk_hat\n",
    "\n",
    "for i in range(0,4):\n",
    "    P_hat.append( (W[i]*n[i,i]/n_idot[i]) / p_dotk_hat[i])\n",
    "\n",
    "print('producers accuracy:', P_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHAT WE WANT: estimate (pixels correctly classified as iceplant)/(pixels are iceplant) for whole map\n",
      " \n",
      "GOAL 1: estimate the fraction of the map that is really iceplant (class 1)\n",
      "Idea: for each class of pixels in map, estimate what fraction of it is really class 1\n",
      "Fraction of pixels from each class in map:\n",
      "W:  [0.2860395334170426, 0.014713838683289604, 0.3953691894823195, 0.30387743841734827] \n",
      "\n",
      "Fraction of samples that are class i in map and class 1 in reference:\n",
      "Information from sample about the fraction from each class in the map that is really class 1\n",
      "n[i,1]/n_idot[i]:  [0.005, 0.6884422110552764, 0.00909090909090909, 0.0] \n",
      "\n",
      "Then we estimate the fraction of each class in the map that is really class 1:\n",
      "W[i]*n[i,1]/n_idot[i] :  [0.0014301976670852128, 0.01012962763623455, 0.0035942653589301774, 0.0]\n",
      "Finally we add these to get an estimate of \n",
      " the total fraction of map that is really class 1\n",
      "p_dot1_hat:  0.015154090662249941 \n",
      "\n",
      "GOAL 2: estimate the fraction of the map that is correctly classified as iceplant\n",
      "this is: fraction of map classified as class 1,\n",
      " multiplied by the sample estimate of the fraction of it is iceplant\n",
      "W[1]:  0.014713838683289604\n",
      "n[1,1]/n_idot[1]:  0.6884422110552764\n",
      "p_11_hat = (W[1]*n[1,1]/n_idot[1]):  0.01012962763623455\n",
      "P_hat = p_11_hat/ p_dot1_hat:  0.6684417997754406\n"
     ]
    }
   ],
   "source": [
    "print('WHAT WE WANT: estimate (pixels correctly classified as iceplant)/(pixels are iceplant) for whole map\\n ')\n",
    "\n",
    "print('GOAL 1: estimate the fraction of the map that is really iceplant (class 1)')\n",
    "print('Idea: for each class of pixels in map, estimate what fraction of it is really class 1')\n",
    "\n",
    "print('Fraction of pixels from each class in map:')\n",
    "print('W: ',W, '\\n')\n",
    "\n",
    "print('Fraction of samples that are class i in map and class 1 in reference:')\n",
    "print('Information from sample about the fraction from each class in the map that is really class 1')\n",
    "print('n[i,1]/n_idot[i]: ', [n[i,1]/n_idot[i] for i in range(0,4) ], '\\n' )\n",
    "\n",
    "print('Then we estimate the fraction of each class in the map that is really class 1:')\n",
    "partial = [W[i]*n[i,1]/n_idot[i] for i in range(0,4) ]\n",
    "print('W[i]*n[i,1]/n_idot[i] : ', partial)\n",
    "\n",
    "print('Finally we add these to get an estimate of \\n the total fraction of map that is really class 1')\n",
    "print('p_dot1_hat: ', p_dotk_hat[1], '\\n')\n",
    "\n",
    "print('GOAL 2: estimate the fraction of the map that is correctly classified as iceplant')\n",
    "print('this is: fraction of map classified as class 1,\\n multiplied by the sample estimate of the fraction of it is iceplant')\n",
    "print('W[1]: ', W[1])\n",
    "print('n[1,1]/n_idot[1]: ',n[1,1]/n_idot[1])\n",
    "print('p_11_hat = (W[1]*n[1,1]/n_idot[1]): ', (W[1]*n[1,1]/n_idot[1]) )\n",
    "print('P_hat = p_11_hat/ p_dot1_hat: ', P_hat[1])\n",
    "#p_dotk_hat.append( sum(partial))  # equation (9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
