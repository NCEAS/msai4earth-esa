{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3132446-b728-4456-bc1f-4ab9faa1602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "import rioxarray as rioxr\n",
    "import rasterio\n",
    "\n",
    "import sample_rasters as sr\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "from shapely.geometry import box\n",
    "\n",
    "import planetary_computer as pc\n",
    "\n",
    "from skimage.feature.texture import greycomatrix, greycoprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea73734-ad00-4dac-9658-0e31c2ee9727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# ************* NOTEBOOK VARIABLES ******************\n",
    "\n",
    "itemids = pd.read_csv(sr.path_to_aoi_itemids_csv())\n",
    "\n",
    "# csv with the points for which to add spectral window features\n",
    "csv_name = 'model3070_test_2020.csv'\n",
    "fp = '/home/jovyan/msai4earth-esa/iceplant_detection/processing_results/model_3070/model3070_test_2020.csv'\n",
    "#fp = os.path.join(os.getcwd(),'temp',csv_name)\n",
    "all_pts = pd.read_csv(fp)\n",
    "\n",
    "entropy_r = 5\n",
    "\n",
    "# ***************************************************\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcff7a18-86e9-486a-9487-21287142e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary folder for aux rasters\n",
    "folp = os.path.join(os.getcwd(),'temp','aux_naip_rasters')\n",
    "if os.path.exists(folp) == False:\n",
    "    os.mkdir(folp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4beda08-f517-4243-968a-ef734224722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED PROCESSINGss\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time() # initial time tracker\n",
    "\n",
    "sampled_pts = [] # sampled pts from each scene are collected here\n",
    "\n",
    "N = len(itemids)  # counter to finish\n",
    "\n",
    "crss = all_pts.pts_crs.unique()\n",
    "\n",
    "for i in range(len(itemids)):\n",
    "    # ---------------------------------------\n",
    "    # open raster reader for NAIP scene\n",
    "    itemid = itemids.itemid[i]\n",
    "    item = sr.get_item_from_id(itemid)    \n",
    "    href = pc.sign(item.assets[\"image\"].href)\n",
    "    naip_rast_r = rioxr.open_rasterio(href) \n",
    "\n",
    "    all_pts_scene = all_pts.loc[all_pts['naip_id'] == itemid]\n",
    "    if len(all_pts_scene) !=0:\n",
    "        for crs_str in crss:\n",
    "            pts_scene = all_pts_scene[all_pts_scene.pts_crs == crs_str]  \n",
    "    \n",
    "            if len(pts_scene) !=0:\n",
    "                crs = CRS.from_string(crs_str)\n",
    "                pts_scene_df = sr.geodataframe_from_csv(df = pts_scene, lon_label='x', lat_label='y', crs=crs)\n",
    "                pts_col = pts_scene_df.to_crs(naip_rast_r.rio.crs).geometry\n",
    "\n",
    "                samples = []\n",
    "                for pt in pts_col:\n",
    "                    # this creates a box centered at point with side length=entropy_r*2 meters\n",
    "                    reduce_box = box(*(pt.buffer(entropy_r).bounds))            \n",
    "                    # clip NAIP scene\n",
    "                    rast = naip_rast_r.rio.clip_box(*reduce_box.bounds)\n",
    "\n",
    "                    # save auxiliary entropy rasters for R,G,B,NIR bands of clipped scene\n",
    "                    band_names = ['r_', 'g_', 'b_', 'nir_']\n",
    "                    tags = ['_entrs']\n",
    "                    window_fps = []\n",
    "                    window_cols = []\n",
    "\n",
    "                    for band_name, band_n in zip(band_names,range(1,5)):\n",
    "                        rast_name = band_name + itemid + '_pt'\n",
    "                        sr.entropy_raster(raster = rast, band=band_n, rast_name=rast_name, n=entropy_r, folder_path=folp)\n",
    "\n",
    "                        for tag in tags:\n",
    "                            window_fps.append(os.path.join(folp, rast_name + tag + '.tif'))        \n",
    "                            window_cols.append( band_name.replace('_','')+tag.replace('s',str(entropy_r)))\n",
    "\n",
    "                    # ------------------------------\n",
    "                    # make auxiliary NDVI of clipped scene\n",
    "                    ndvi = sr.ndvi_xarray(rast)\n",
    "\n",
    "                    # make auxiliary NDVI entropy\n",
    "                    band_names.append('ndvi_')\n",
    "                    rast_name = 'ndvi_' + itemid + '_pt'\n",
    "\n",
    "                    # adjusting to entropy input types\n",
    "                    ndvi = ndvi*100 +100\n",
    "                    sr.entropy_raster(rast_data=ndvi.astype('uint8'), \n",
    "                                      crs=rast.rio.crs, \n",
    "                                      transf=rast.rio.transform(), \n",
    "                                      rast_name=rast_name, \n",
    "                                      n=entropy_r, \n",
    "                                      folder_path=folp)\n",
    "\n",
    "                    for tag in tags:\n",
    "                        window_fps.append(os.path.join(folp, rast_name + tag + '.tif'))        \n",
    "                        window_cols.append( 'ndvi'+tag.replace('s',str(entropy_r)))\n",
    "\n",
    "                    # ---------------------------------------\n",
    "                    # sample raster values for points in this scene\n",
    "                    pt_samples = []\n",
    "                    for fp, col_name in zip(window_fps, window_cols):\n",
    "                        rast_r = rasterio.open(fp)\n",
    "                        pt_df = gpd.GeoDataFrame({'geometry':[pt]}, crs=pts_col.crs)\n",
    "                        sample = sr.sample_raster_from_pts(pt_df.geometry, rast_r, [col_name])    \n",
    "                        pt_samples.append(sample)\n",
    "                        os.remove(fp)\n",
    "                    samples.append(pd.concat(pt_samples, axis=1))\n",
    "                # ---------------------------------------\n",
    "                # Add all derived spectral data to pts dataframe\n",
    "                new_features = pd.concat(samples)\n",
    "                pts = pd.concat([pts_scene, new_features.set_index(pts_col.index)], axis=1)                \n",
    "\n",
    "                # -----------------------------\n",
    "                # collect all points from each polygon in the scene\n",
    "                sampled_pts.append(pts)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # processing message\n",
    "    N = N-1                \n",
    "    print('REMAINING: ', N, 'scenes', end=\"\\r\")\n",
    "\n",
    "print('FINISHED PROCESSING')       \n",
    "     \n",
    "# ---------------------------------------\n",
    "# create data frame with all points\n",
    "sampled_pts= pd.concat(sampled_pts).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77cf0ab1-4c57-45dd-8332-6c9afcd8e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_pts = sampled_pts[['x', 'y', 'pts_crs', #  point location\n",
    "             'aoi', 'naip_id', 'polygon_id',  # sampling info\n",
    "             'r', 'r_max', 'r_min', 'r_diff', 'r_avg', 'r_entr', # spectral\n",
    "             'g', 'g_max', 'g_min', 'g_diff', 'g_avg', 'g_entr',\n",
    "             'b', 'b_max', 'b_min', 'b_diff', 'b_avg', 'b_entr',\n",
    "             'nir', 'nir_max', 'nir_min', 'nir_diff', 'nir_avg', 'nir_entr',\n",
    "             'ndvi', 'ndvi_max', 'ndvi_min', 'ndvi_diff', 'ndvi_avg', 'ndvi_entr',   \n",
    "             'year', 'month', 'day_in_year', # date\n",
    "            'r_entr5','g_entr5', 'b_entr5', 'nir_entr5', 'ndvi_entr5',                          \n",
    "             'iceplant'\n",
    "             ]] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d97fd72-e36e-42e7-8073-bcfc55521d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x', 'y', 'pts_crs', 'aoi', 'naip_id', 'polygon_id', 'r', 'r_max',\n",
       "       'r_min', 'r_diff', 'r_avg', 'r_entr', 'g', 'g_max', 'g_min', 'g_diff',\n",
       "       'g_avg', 'g_entr', 'b', 'b_max', 'b_min', 'b_diff', 'b_avg', 'b_entr',\n",
       "       'nir', 'nir_max', 'nir_min', 'nir_diff', 'nir_avg', 'nir_entr', 'ndvi',\n",
       "       'ndvi_max', 'ndvi_min', 'ndvi_diff', 'ndvi_avg', 'ndvi_entr', 'year',\n",
       "       'month', 'day_in_year', 'r_entr5', 'g_entr5', 'b_entr5', 'nir_entr5',\n",
       "       'ndvi_entr5', 'iceplant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_pts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d434e9-87fd-49e3-8f53-ebab38a93eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join(os.getcwd(),'temp', 'spectral_window_'+csv_name)\n",
    "sampled_pts.to_csv(fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3957a33c-faab-4cbd-869a-eb8bbf2442b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
