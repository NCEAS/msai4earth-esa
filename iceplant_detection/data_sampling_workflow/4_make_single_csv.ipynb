{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa89fce3-0450-4190-a2ba-3af09e400f3e",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This notebook assembles all the csvs produced by the `3_add_lidar.ipynb` notebook into a single dataframe and saves it as a single csv. It also includes some statistics of the combined dataset. The notebook assumes all the posisble aois and years have been sampled and have a csv of points associated with them.\n",
    "\n",
    "**VARIABLES**\n",
    "\n",
    "`delete_files` (bool): whether to delete the individual csvs from which the final dataset is assembled\n",
    "\n",
    "**OUTPUT:**\n",
    "A single csv named 'samples_for_model.csv'. This contains all the points with all the features sampled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7a7815d-4fe8-4c41-b3d6-9c10af6995e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from utility import iceplant_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e5fbb-1a44-4b8c-b7d4-0df68eef2e10",
   "metadata": {},
   "source": [
    "# Specify notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b83bca10-f788-490f-9cff-bd1fc5a5cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# ************* NOTEBOOK VARIABLES ******************\n",
    "\n",
    "delete_files = False\n",
    "\n",
    "# ***************************************************\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207d4a1a-7f56-4aec-8566-ddac8a30bf28",
   "metadata": {},
   "source": [
    "# Assemble data frame with all sampled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "419e2adc-a221-4f89-9cf9-8228db7a6b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def path_spectral_points_csv(aoi, year):\n",
    "    \"\"\" Assembles a file path to file with points and ONLY spectral information from given aoi and year. \"\"\"\n",
    "    fp = os.path.join(os.getcwd(), \n",
    "                      'temp',\n",
    "                      aoi +'_points_'+str(year)+'.csv')\n",
    "    return fp            \n",
    "\n",
    "#---------------------\n",
    "\n",
    "def path_lidar_spectral_points_csv(aoi, year):\n",
    "    \"\"\" Assembles a file path to file with points and canopy height AND spectral information from given aoi and year. \"\"\"\n",
    "    fp = os.path.join(os.getcwd(), \n",
    "                      'temp',\n",
    "                      aoi +'_pts_spectral_lidar_'+str(year)+'.csv')\n",
    "    return fp            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f76317c0-f7f8-4969-be67-3b0cfcdefe68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lidar_years = [2016,2018,2020]\n",
    "spec_years = [2012,2014]\n",
    "aois = ['campus_lagoon','carpinteria','gaviota','point_conception']\n",
    "\n",
    "# *******************************************************************************\n",
    "# Open and concatenate csv files of points with canopy height + spectral info\n",
    "li = []\n",
    "for aoi in aois:\n",
    "    for year in lidar_years:\n",
    "        if ('point_conception' != aoi) or (year != 2016):  #there's no data for Point Conception on 2016\n",
    "            sample = pd.read_csv(path_lidar_spectral_points_csv(aoi,year))\n",
    "            li.append(sample)\n",
    "\n",
    "df_lidar = pd.concat(li, axis=0)\n",
    "\n",
    "# only keep points with non-negative canopy height values\n",
    "df_lidar = df_lidar.loc[(df_lidar[\"lidar\"] >= 0) & \n",
    "                        (df_lidar[\"max_lidar\"] >= 0) &\n",
    "                        (df_lidar[\"min_lidar\"] >= 0) &\n",
    "                        (df_lidar[\"avg_lidar\"] >= 0) &\n",
    "                        (df_lidar[\"min_max_diff\"] >= 0)\n",
    "                       ]\n",
    "\n",
    "# *******************************************************************************\n",
    "# Open and concatenate csv files of points with canopy height + spectral info\n",
    "li = []\n",
    "for aoi in aois:\n",
    "    for year in spec_years:\n",
    "            sample = pd.read_csv(path_spectral_points_csv(aoi,year))\n",
    "            li.append(sample)\n",
    "\n",
    "df_spec = pd.concat(li, axis=0)\n",
    "\n",
    "# fill in canopy height columns wit NaN\n",
    "df_spec['lidar'] = np.nan\n",
    "df_spec['max_lidar'] = np.nan\n",
    "df_spec['min_lidar'] = np.nan\n",
    "df_spec['avg_lidar'] = np.nan\n",
    "df_spec['min_max_diff'] = np.nan\n",
    "\n",
    "# *******************************************************************************\n",
    "# concatenate both data frames and clean index and columns\n",
    "df = pd.concat([df_lidar,df_spec], axis=0)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df = df[['x', 'y', 'pts_crs', #  point location\n",
    "         'aoi','naip_id', 'polygon_id',  # sampling info\n",
    "         'r','g','b','nir','ndvi',     # spectral\n",
    "         'year','month','day_in_year', # date\n",
    "         'lidar', 'max_lidar', 'min_lidar', 'min_max_diff', 'avg_lidar', # lidar\n",
    "         'iceplant'\n",
    "         ]] \n",
    "\n",
    "# *******************************************************************************\n",
    "# save data frame as csv\n",
    "df.to_csv(os.path.join(os.getcwd(),'samples_for_model.csv'), index=False)\n",
    "\n",
    "\n",
    "# *******************************************************************************\n",
    "# Delete individual files\n",
    "if delete_files == True:\n",
    "    for aoi in aois:\n",
    "        for year in years:\n",
    "            if year in spec_years:\n",
    "                os.remove(path_spectral_points_csv(aoi,year))\n",
    "            if year in lidar_years:\n",
    "                if ('point_conception' != aoi) or (year != 2016):  #there's no data for Point Conception on 2016\n",
    "                    os.remove(path_lidar_spectral_points_csv(aoi,year))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c24726e-83a8-4c5e-8f22-b863d89cbafd",
   "metadata": {},
   "source": [
    "# Statistics about data distribution\n",
    "## non-ice plant : iceplant proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3676e87e-d074-439c-8ce4-ddb59427771a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no-iceplant:iceplant ratio     1.8 :1\n",
      "          counts  percentage\n",
      "iceplant                    \n",
      "0         313132        63.8\n",
      "1         177691        36.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iceplant_proportions(df.iceplant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944e0ff3-8acc-42a8-b6f1-35dbf8932d62",
   "metadata": {},
   "source": [
    "## Number of points by area of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b34a791-4db3-43b5-a5e1-f1dcbb957eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "point_conception    192684\n",
       "campus_lagoon       132816\n",
       "carpinteria         102192\n",
       "gaviota              63131\n",
       "Name: aoi, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking all data was loaded\n",
    "df.aoi.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ca1a4-077f-4f87-8069-ac921af7c91b",
   "metadata": {},
   "source": [
    "## Number of points by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "478f26de-fa69-4964-ac15-b742cefe6450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020    150684\n",
       "2018    121937\n",
       "2014     89193\n",
       "2012     77247\n",
       "2016     51762\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e678411-720a-4c56-9263-ba99b19fed49",
   "metadata": {},
   "source": [
    "## Number of points by NAIP scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a0d6fb6-473b-42da-9863-0aa7d5936689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ca_m_3412037_nw_10_060_20200607             81605\n",
       "ca_m_3411934_sw_11_060_20180722_20190209    54950\n",
       "ca_m_3412037_nw_10_1_20140603_20141030      50853\n",
       "ca_m_3412037_nw_10_1_20120518_20120730      31965\n",
       "ca_m_3412037_nw_10_060_20180913_20190208    28261\n",
       "ca_m_3411936_se_11_060_20200521             27995\n",
       "ca_m_3411934_sw_11_060_20200521             25767\n",
       "ca_m_3411936_se_11_060_20180724_20190209    23836\n",
       "ca_m_3411934_sw_11_.6_20160713_20161004     20283\n",
       "ca_m_3411936_se_11_.6_20160713_20161004     18421\n",
       "ca_m_3411934_sw_11_1_20120505_20120730      18379\n",
       "ca_m_3411936_se_11_1_20120505_20120730      16576\n",
       "ca_m_3411936_se_11_1_20140901_20141030      15364\n",
       "ca_m_3412039_nw_10_060_20200522             15317\n",
       "ca_m_3412039_nw_10_060_20180724_20190209    14890\n",
       "ca_m_3411934_sw_11_1_20140601_20141030      13437\n",
       "ca_m_3412039_nw_10_.6_20160616_20161004     13058\n",
       "ca_m_3412039_nw_10_1_20120518_20120730      10327\n",
       "ca_m_3412039_nw_10_1_20140603_20141030       9539\n",
       "Name: naip_id, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.naip_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e483c34b-e2bb-490b-be03-04e813fb1932",
   "metadata": {},
   "source": [
    "## Number of NAIP scenes sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad48241d-c5b9-4a61-82a2-d5a9e0d46d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.naip_id.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
