{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7857bfb-d31c-4c6b-937f-0f14b338b79c",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This notebook extracts spectral and date features of NAIP images at random points within polygons in the 'polygons_form_naip_images' folder. These polygons are known ice plant and non ice plant locations within a specific NAIP image. \n",
    "\n",
    "\n",
    "Once the area of interest and years are specified, the notebook samples first polygons labeled as ice plant locations and then polygons labeled as non-ice plant locations. Two methods for sampling polygons are implemented in the `extracting_points_from_polygons` module, and both are used in this notebook. The first one samples a fixed fraction of the points in each polygon. The second one samples a fixed fraction of the points in each polygon up to a maximum number of points. Polygons vary significantly in size, so simply sampling a fraction of the points in each polygon would result in an over-sampling of bigger polygons (most often those corresponding to non-ice plant locations), which in turn would unbalance the training set towards one label. The parameters used in this notebook were determined to obtain a final training set with a XXX proportion of non-ice plant to ice plant points. \n",
    "\n",
    "**NOTEBOOK VARIABLES:**\n",
    "\n",
    "- `aois` (array): These are the areas of interest where we collected the polygons we want to sample. Must be a subset of: `['campus_lagoon','carpinteria','gaviota','point_conception']`. \n",
    "\n",
    "- `years` (array): can be any subset of `[2012, 2014, 2016, 2018, 2020]`. If aoi = 'point_conception', then 2016 will not be included in the outcome since there are no NAIP images to sample from that year. \n",
    "\n",
    "- `sample_fraction` (float in (0,1]): fraction of points to sample from each polygon\n",
    "\n",
    "- `max_sample` (int): maximum number of points to sample from a polygon\n",
    "\n",
    "- `verbose` (bool): whether to print the stats of how many points were sampled per year and area of interest as the notebook runs\n",
    "\n",
    "- `write_stats` (bool): whether to save as a csv file the stats of how many points were sampled from each year and area of interest\n",
    "\n",
    "**OUTPUT:**\n",
    "\n",
    "The output is a data frame of points with the following features:\n",
    "\n",
    "- x, y: coordinates of point *p* \n",
    "- pts_crs: CRS of coordinates x, y\n",
    "- naip_id: itemid of the NAIP from which *p* was sampled from\n",
    "- polygon_id: id of the polygon from which *p* was sampled from\n",
    "- iceplant: whether point *p* corresponds to a confirmed iceplant location or a confirmed non-iceplant location (0 = non-iceplant, 1 = iceplant)\n",
    "- r, g, b, nir: Red, Green, Blue, and NIR values of NAIP scene with naip_id at coordinates of point *p*\n",
    "- ndvi: computed for each point using the Red and NIR bands\n",
    "- year, month, day_in_year: year, month, and day of the year when the NAIP image was collected\n",
    "- aoi: name of the area of interest where the points were sampled from\n",
    "\n",
    "\n",
    "The data frames are saved in the 'temp' folder as a csv file. Filenames have the structure: `aoi_points_year.csv'`\n",
    "The stats are saved in the temp folder as `stats_1_sampling_pts_from_polygons.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d21b9a0-c9a8-44fb-9f3f-b07fa5cf2a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "import sample_rasters as sr\n",
    "import utility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537b008-3fab-4251-94ad-177503dab258",
   "metadata": {},
   "source": [
    "# Specify notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a1d84e-4b5d-4606-aea2-a14747078dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# ************* NOTEBOOK VARIABLES ******************\n",
    "\n",
    "aois = ['campus_lagoon','carpinteria','gaviota','point_conception']\n",
    "\n",
    "# years = array of years, can be any subset from [2012, 2014, 2016, 2018, 2020]\n",
    "years = [2012, 2014, 2016, 2018, 2020]\n",
    "\n",
    "# sample 90% of pts in each polygon\n",
    "sample_fraction = 0.9\n",
    "\n",
    "# maximum number of pts to sample in a polygon\n",
    "max_sample = 1000\n",
    "\n",
    "# print stats as notebook runs\n",
    "verbose = False\n",
    "\n",
    "# save stats\n",
    "write_stats = True\n",
    "\n",
    "# ***************************************************\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0982a96a-4bc1-44e4-a28b-b35b207fdc3b",
   "metadata": {},
   "source": [
    "# Sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d556071-2a4e-4714-a2e2-952315d042d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize sampling statistcs df\n",
    "if write_stats:\n",
    "    stats = []\n",
    "\n",
    "# sample points\n",
    "for aoi in aois:\n",
    "    for year in years:\n",
    "        \n",
    "        if ('point_conception' != aoi) or (year != 2016):  #there's no data for Point Conception on 2016\n",
    "            \n",
    "            # open polygons\n",
    "            fp = sr.path_to_polygons(aoi,year)\n",
    "            polys = gpd.read_file(fp)\n",
    "            # -------------------------\n",
    "            # select iceplant polygons and sample sample_fraction of pts in each polygon \n",
    "            polys_ice = polys.loc[polys.iceplant==1]\n",
    "            polys_ice.reset_index(inplace=True, drop=True)\n",
    "            \n",
    "            pts_ice = sr.sample_naip_from_polys_no_warnings(polys = polys_ice,\n",
    "                                                            class_name = 'iceplant',\n",
    "                                                            itemid = polys.naip_id[0], \n",
    "                                                            param = 'fraction',\n",
    "                                                            sample_fraction = sample_fraction)  \n",
    "            # -------------------------\n",
    "            # select non-iceplant polygons and sample sample_fraction of pts in each polygon,  but at most max_sample points \n",
    "            polys_nonice = polys.loc[polys.iceplant==0]\n",
    "            polys_nonice.reset_index(inplace=True, drop=True)\n",
    "            \n",
    "            pts_nonice = sr.sample_naip_from_polys_no_warnings(polys = polys_nonice,\n",
    "                                                            class_name = 'iceplant',\n",
    "                                                            itemid = polys.naip_id[0], \n",
    "                                                            param = 'sliding',\n",
    "                                                            sample_fraction = sample_fraction,\n",
    "                                                            max_sample = max_sample)  \n",
    "            # -------------------------            \n",
    "            # assemble into single dataframe\n",
    "            pts = pd.concat([pts_ice,pts_nonice])\n",
    "            pts['aoi'] = aoi # add name of aoi\n",
    "            pts['ndvi']=(pts.nir.astype('int16') - pts.r.astype('int16'))/(pts.nir.astype('int16') + pts.r.astype('int16'))# add ndvi as feature\n",
    "\n",
    "            # -------------------------           \n",
    "            # save points as csv in temp folder            \n",
    "            tmp_path = os.path.join(os.getcwd(),'temp')  # create temp directory if needed\n",
    "            if not os.path.exists(tmp_path):\n",
    "                os.makedirs(tmp_path)\n",
    "            \n",
    "            # change to function\n",
    "            fp = sr.path_to_spectral_pts(aoi, year)\n",
    "            pts.to_csv(fp, index=False)\n",
    "            \n",
    "            # -------------------------\n",
    "            # print sample statistics\n",
    "            if verbose == True:\n",
    "                print('************ '+aoi+ ' ' +str(year)+' ************')\n",
    "                utility.iceplant_proportions(pts.iceplant)\n",
    "                print( '---------------------------------------')\n",
    "                \n",
    "            # -------------------------\n",
    "            # keep track of statistics for saving\n",
    "            if write_stats == True:\n",
    "                n_ice =  pts_ice.shape[0]\n",
    "                n_nonice =  pts_nonice.shape[0]\n",
    "                total = n_ice + n_nonice\n",
    "                \n",
    "                stat = [aoi, \n",
    "                     year, \n",
    "                     str(round(n_nonice/n_ice,1))+':1', \n",
    "                     round(n_ice/total*100,2),\n",
    "                     round(n_nonice/total*100,2),\n",
    "                     n_ice,\n",
    "                     n_nonice\n",
    "                    ]\n",
    "                stats.append(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec4bf255-5df2-4e3d-8a84-d7efa2855bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_stats:     \n",
    "    stats_df = pd.DataFrame(stats, \n",
    "                            columns=['aoi', 'year', 'ratio','perc_ice','perc_nonice','n_ice','n_nonice'])\n",
    "\n",
    "    # save points as csv in temp folder\n",
    "    fp = os.path.join(os.getcwd(), \n",
    "                      'temp', \n",
    "                      'stats_1_sampling_pts_from_polygons.csv')\n",
    "    stats_df.to_csv(fp, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
