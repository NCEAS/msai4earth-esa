{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7857bfb-d31c-4c6b-937f-0f14b338b79c",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This notebook extracts spectral and date features of NAIP images at random points within polygons in the 'polygons_form_naip_images' folder. These polygons are known ice plant and non ice plant locations within a specific NAIP image. \n",
    "\n",
    "\n",
    "Once the aoi and years are specified, the notebook samples first polygons labeled as ice plant locations and then polygons labeled as non-ice plant locations. Two methods for sampling polygons are implemented in the `extracting_points_from_polygons,` and both are used in this notebook. The first one, `naip_sample_proportion`, samples a fixed fraction of the points in each polygon. The second one, `naip_sample_sliding`, samples a fixed fraction of the points in each polygon up to a maximum number of points. Polygons vary greatly in size, so simply sampling a fraction of the points in each polygon would result in an over-sampling of bigger polygons (most often those corresponding to non-ice plant locations), which in turn would unbalance the training set towards one label. The parameters used in this notebook were determined to obtain a final training set with a 3:1 proportion of non-ice plant to ice plant points. \n",
    "\n",
    "**NOTEBOOK VARIABLES:**\n",
    "\n",
    "- `aois` (array): These are the areas of interest from which the polygons we want to sample were collected. Must be a subset of: `['campus_lagoon','carpinteria','gaviota','point_conception']`. \n",
    "\n",
    "- `years` (array): can be any subset from `[2012, 2014, 2016, 2018, 2020]`. If aoi = 'point_conception' then 2016 will not be included in the outcome since there are not points to NAIP images to sample from on that year. \n",
    "\n",
    "- `sample_fraction` (float in (0,1]): fraction of points to sample from each polygon\n",
    "\n",
    "- `max_sample` (int): maximum number of points to sample from a polygon\n",
    "\n",
    "- `verbose` (bool): whether to print as the notebook runs the stats of how many points were sampled per year and aoi \n",
    "\n",
    "- `write_stats` (bool): whether to save as a csv the stats of how many points were sampled from each aoi and year\n",
    "\n",
    "**OUTPUT:**\n",
    "\n",
    "The output is a dataframe of points with the following features:\n",
    "\n",
    "- geometry: coordinates of point *p* in the NAIP image's CRS\n",
    "- naip_id: itemid of the NAIP from which *p* was sampled from\n",
    "- polygon_id: id of the polygon from which *p* was sampled from\n",
    "- iceplant: whether point *p* corresponds to a confirmed iceplant location or a confirmed non-iceplant location (0 = non-iceplant, 1 = iceplant)\n",
    "- r, g, b, nir: Red, Green, Blue and NIR bands values of NAIP scene with naip_id at at cooridnates of point *p*\n",
    "- ndvi: computed for each point using the Red and NIR bands\n",
    "- year, month, day_in_year: year, month and day of the year when the NAIP image was collected\n",
    "- aoi: name of the area of interest where the points were sampled from\n",
    "\n",
    "\n",
    "The dataframe is then saved in the 'temp' folder as a csv file. Filenames have the structure: `aoi_points_year.csv'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d21b9a0-c9a8-44fb-9f3f-b07fa5cf2a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "import extracting_points_from_polygons as pp\n",
    "import utility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537b008-3fab-4251-94ad-177503dab258",
   "metadata": {},
   "source": [
    "# Specify notebook variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a1d84e-4b5d-4606-aea2-a14747078dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# ************* NOTEBOOK VARIABLES ******************\n",
    "\n",
    "#aois = ['campus_lagoon','carpinteria','gaviota','point_conception']\n",
    "aois = ['campus_lagoon','carpinteria']\n",
    "\n",
    "\n",
    "# years = array of years, can be any subset from [2012, 2014, 2016, 2018, 2020]\n",
    "#years = [2012, 2014, 2016, 2018, 2020]\n",
    "years = [2018,2020]\n",
    "\n",
    "# sample 90% of pts in each polygon\n",
    "sample_fraction = 0.9\n",
    "\n",
    "# maximum number of pts to sample in a polygon\n",
    "max_sample = 1000\n",
    "\n",
    "# print stats as notebook runs\n",
    "verbose = False\n",
    "\n",
    "# save stats\n",
    "write_stats = True\n",
    "\n",
    "\n",
    "# ***************************************************\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0982a96a-4bc1-44e4-a28b-b35b207fdc3b",
   "metadata": {},
   "source": [
    "# Sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b192b4c-5bf5-470d-83e4-bf9b68669536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ campus_lagoon 2018 ************\n",
      "no-iceplant:iceplant ratio     6.6 :1\n",
      "          counts  percentage\n",
      "iceplant                    \n",
      "0          47693       86.79\n",
      "1           7257       13.21\n",
      "\n",
      "---------------------------------------\n",
      "************ campus_lagoon 2020 ************\n",
      "no-iceplant:iceplant ratio     1.9 :1\n",
      "          counts  percentage\n",
      "iceplant                    \n",
      "0          17000       65.98\n",
      "1           8767       34.02\n",
      "\n",
      "---------------------------------------\n",
      "************ carpinteria 2018 ************\n",
      "no-iceplant:iceplant ratio     2.7 :1\n",
      "          counts  percentage\n",
      "iceplant                    \n",
      "0          17448        73.2\n",
      "1           6388        26.8\n",
      "\n",
      "---------------------------------------\n",
      "************ carpinteria 2020 ************\n",
      "no-iceplant:iceplant ratio     1.7 :1\n",
      "          counts  percentage\n",
      "iceplant                    \n",
      "0          17448       62.33\n",
      "1          10547       37.67\n",
      "\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# initialize sampling statistcs df\n",
    "if write_stats:\n",
    "    stats = []\n",
    "\n",
    "# sample points\n",
    "for aoi in aois:\n",
    "    for year in years:\n",
    "        \n",
    "        if ('point_conception' != aoi) or (year != 2016):  #there's no data for Point Conception on 2016\n",
    "            \n",
    "            # open polygons\n",
    "            fp = pp.path_to_polygons(aoi,year)\n",
    "            polys = gpd.read_file(fp)\n",
    "            \n",
    "            # select iceplant polygons and sample sample_fraction of pts in each polygon \n",
    "            polys_ice = polys.loc[polys.iceplant==1]\n",
    "            polys_ice.reset_index(inplace=True, drop=True)\n",
    "\n",
    "            pts_ice = pp.naip_sample_proportion_no_warnings(polys_ice, \n",
    "                                                            polys.naip_id[0], \n",
    "                                                            sample_fraction)  \n",
    "            \n",
    "            # select non-iceplant polygons and sample sample_fraction of pts in each polygon,  but at most max_sample points \n",
    "            polys_nonice = polys.loc[polys.iceplant==0]\n",
    "            polys_nonice.reset_index(inplace=True, drop=True)\n",
    "\n",
    "            pts_nonice = pp.naip_sample_sliding_no_warnings(polys_nonice, polys.naip_id[0], \n",
    "                                                            sample_fraction, \n",
    "                                                            max_sample)\n",
    "            # assemble into single dataframe\n",
    "            pts = pd.concat([pts_ice,pts_nonice])\n",
    "\n",
    "            # add name of aoi\n",
    "            pts['aoi'] = aoi\n",
    "            \n",
    "            # add ndvi as feature\n",
    "            pts['ndvi']=(pts.nir.astype('int16') - pts.r.astype('int16'))/(pts.nir.astype('int16') + pts.r.astype('int16'))\n",
    "\n",
    "           \n",
    "            # create temp directory if needed\n",
    "            tmp_path = os.path.join(os.getcwd(),'temp')\n",
    "            if not os.path.exists(tmp_path):\n",
    "                os.makedirs(tmp_path)\n",
    "            \n",
    "            # save points as csv in temp folder\n",
    "            fp = os.path.join(os.getcwd(), \n",
    "                              'temp', \n",
    "                              aoi + '_points_'+str(year)+'.csv')\n",
    "            pts.to_csv(fp, index=False)\n",
    "            \n",
    "            # print sample statistics\n",
    "            if verbose == True:\n",
    "                # print sample information\n",
    "                print('************ '+aoi+ ' ' +str(year)+' ************')\n",
    "                utility.iceplant_proportions(pts.iceplant)\n",
    "                print( '---------------------------------------')\n",
    "                \n",
    "            if write_stats == True:\n",
    "                n_ice =  pts_ice.shape[0]\n",
    "                n_nonice =  pts_nonice.shape[0]\n",
    "                total = n_ice + n_nonice\n",
    "                \n",
    "                stat = [aoi, \n",
    "                     year, \n",
    "                     str(round(n_nonice/n_ice,1))+':1', \n",
    "                     round(n_ice/total*100,2),\n",
    "                     round(n_nonice/total*100,2),\n",
    "                     n_ice,\n",
    "                     n_nonice\n",
    "                    ]\n",
    "                stats.append(stat)\n",
    "                \n",
    "                \n",
    "if write_stats:     \n",
    "    stats_df = pd.DataFrame(stats, \n",
    "                            columns=['aoi', 'year', 'ratio','perc_ice','perc_nonice','n_ice','n_nonice'])\n",
    "\n",
    "    # save points as csv in temp folder\n",
    "    fp = os.path.join(os.getcwd(), \n",
    "                      'temp', \n",
    "                      'stats_1_sampling_pts_from_polygons.csv')\n",
    "    stats_df.to_csv(fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238380d0-a083-4a29-9aee-5c91d61eae50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
