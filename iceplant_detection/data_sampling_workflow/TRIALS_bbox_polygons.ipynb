{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47801f9-46e8-4bb2-8980-dbc487f35af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "import rioxarray as rioxr\n",
    "import rasterio\n",
    "\n",
    "#from skimage.filters.rank import entropy\n",
    "import sample_rasters as sr\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "from shapely.geometry import box\n",
    "\n",
    "import planetary_computer as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f215e68-dae4-40b2-b7a4-798f2c10a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# ************* NOTEBOOK VARIABLES ******************\n",
    "\n",
    "itemids = pd.read_csv(os.path.join(os.getcwd(),'temp', 'aoi_naip_itemids.csv'))\n",
    "\n",
    "csv_name = 'spectral_window_test_set.csv'\n",
    "all_pts = pd.read_csv(os.path.join(os.getcwd(), csv_name))\n",
    "\n",
    "# ***************************************************\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f3aaa-6fdc-434f-b571-0bdd1f1d971b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca68c8c9-5678-45b0-9f85-656d8a7336ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary folder for aux rasters\n",
    "folp = os.path.join(os.getcwd(),'temp','aux_naip_rasters')\n",
    "if os.path.exists(folp) == False:\n",
    "    os.mkdir(folp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff94901d-5c85-4799-9a16-3ec2e7025172",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "sampled_pts = []\n",
    "#for i in [9]:\n",
    "for i in range(len(itemids)):\n",
    "    # ---------------------------------------\n",
    "    # open raster reader for NAIP scene\n",
    "    itemid = itemids.itemid[i]\n",
    "    item = sr.get_item_from_id(itemid)    \n",
    "    href = pc.sign(item.assets[\"image\"].href)\n",
    "    naip_rast_r = rioxr.open_rasterio(href) \n",
    "\n",
    "    # ---------------------------------------\n",
    "    # find polygons for that NAIP scene\n",
    "    poly_fp = sr.path_to_polygons(itemids.iloc[i].aoi_name, itemids.iloc[i].year)\n",
    "    polys = gpd.read_file(poly_fp)\n",
    "    \n",
    "    polys_pts = []\n",
    "    # iterate through polygons in scene\n",
    "#    for j in [0]:\n",
    "    for j in range(len(polys)):\n",
    "        # ---------------------------------------\n",
    "        # create enlarged bounding box\n",
    "        poly = polys.geometry[j]\n",
    "        reduce = gpd.GeoDataFrame({'geometry':[box(*poly.bounds)]}, crs=polys.crs)\n",
    "        reduce = reduce.to_crs(naip_rast_r.rio.crs) \n",
    "        poly = reduce.geometry[0]  # poly in scene's crs\n",
    "        reduce_box = box(*(poly.buffer(6).bounds)) # n must be 2*(entropy disk radius)\n",
    "        \n",
    "        # ---------------------------------------\n",
    "        # clip NAIP scene\n",
    "        rast = naip_rast_r.rio.clip_box(*reduce_box.bounds)\n",
    "        \n",
    "        # ---------------------------------------\n",
    "        # save auxiliary entropy rasters for R,G,B,NIR bands of clipped scene\n",
    "        band_names = ['r_', 'g_', 'b_', 'nir_']\n",
    "        tags = ['_entrs']\n",
    "        window_fps = []\n",
    "        window_cols = []\n",
    "        \n",
    "        for band_name, band_n in zip(band_names,range(1,5)):\n",
    "            rast_name = band_name + itemid + '_poly_'+str(j)\n",
    "            sr.entropy_raster(raster = rast, band=band_n, rast_name=rast_name, n=3, folder_path=folp)\n",
    "\n",
    "            for tag in tags:\n",
    "                window_fps.append(os.path.join(folp, rast_name + tag + '.tif'))        \n",
    "                window_cols.append( band_name.replace('_','')+tag.replace('s',''))\n",
    "                \n",
    "        # ------------------------------\n",
    "        # make auxiliary NDVI of clipped scene\n",
    "        t0 = time.time()\n",
    "        red_band = rast.sel(band=1).astype('int16') \n",
    "        nir_band = rast.sel(band=4).astype('int16')\n",
    "        ndvi = ((nir_band - red_band) / (nir_band + red_band)*100)+100\n",
    "        \n",
    "        # make auxiliary NDVI entropy\n",
    "        band_names.append('ndvi_')\n",
    "        rast_name = 'ndvi_' + itemid + '_poly_'+str(j)\n",
    "        sr.entropy_raster(rast_data=ndvi.astype('uint8'),\n",
    "                          crs=rast.rio.crs, \n",
    "                          transf=rast.rio.transform(), \n",
    "                          rast_name=rast_name, \n",
    "                          n=3, \n",
    "                          folder_path=folp)\n",
    "\n",
    "        for tag in tags:\n",
    "            window_fps.append(os.path.join(folp, rast_name + tag + '.tif'))        \n",
    "            window_cols.append( 'ndvi'+tag.replace('s',''))\n",
    "        \n",
    "        # ---------------------------------------\n",
    "        # find points in current polygon\n",
    "        pts_poly = all_pts.loc[ (all_pts['naip_id'] == itemid) & (all_pts['polygon_id'] == j)]\n",
    "        crs = CRS.from_string(pts_poly.pts_crs.iloc[0])\n",
    "        pts_poly_df = sr.geodataframe_from_csv(df = pts_poly, lon_label='x', lat_label='y', crs=crs)\n",
    "        pts_col = pts_poly_df.to_crs(naip_rast_r.rio.crs).geometry\n",
    "\n",
    "        # ---------------------------------------\n",
    "        # sample raster values for points in current polygon\n",
    "        samples = []\n",
    "        for fp, col_name in zip(window_fps, window_cols):\n",
    "            rast_r = rasterio.open(fp)\n",
    "            sample = sr.sample_raster_from_pts(pts_col, rast_r, [col_name])    \n",
    "            samples.append(sample)\n",
    "            \n",
    "        # ---------------------------------------\n",
    "        # Add all derived spectral data to pts dataframe\n",
    "        new_features = pd.concat(samples, axis = 1)\n",
    "        pts = pd.concat([pts_poly, new_features.set_index(pts_poly_df.index)], axis=1)                \n",
    "        \n",
    "        # -----------------------------\n",
    "        # collect all points from each polygon in the scene\n",
    "        polys_pts.append(pts)\n",
    "        \n",
    "        # ---------------------------------------\n",
    "        # delete aux entropy rasters\n",
    "        for fp in window_fps:\n",
    "            os.remove(fp)\n",
    "            \n",
    "sampled_pts= pd.concat(polys_pts).sort_index()\n",
    "        \n",
    "print(time.time() -t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ab67e6-e94d-4961-8678-c16cc8a95fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743b93f-c472-4252-af98-d2fb2436320f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
