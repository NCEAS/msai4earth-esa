{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22271604-a3d1-4887-bb60-b519c6aad648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc   # garbage collector\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "import rioxarray as rioxr\n",
    "\n",
    "import dask_gateway\n",
    "import dask.array as da\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "# custom modules\n",
    "import raster_to_features as rf\n",
    "import data_sampling_workflow.sample_rasters as sr\n",
    "\n",
    "from skimage.feature import graycomatrix, graycoprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9190925a-4975-4545-bad8-78498a2e8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year for which to predict iceplant locations\n",
    "year = 2020\n",
    "window_r = 5\n",
    "\n",
    "# whether to apply median filter to raster\n",
    "filter_rasters = True\n",
    "\n",
    "# whether to save rasters\n",
    "save_rasters = True\n",
    "prefix = 'glcm2020_model'\n",
    "\n",
    "\n",
    "# whether to print processing info at runtime\n",
    "verbose = False\n",
    "\n",
    "save_processing_times = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b6fc66-a393-4f8d-96e4-f75a9b77104e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# **************************************************************\n",
    "# open shapefile of SB coastal buffer and process it to use it for clipping\n",
    "fp = os.path.join(os.getcwd(), \n",
    "                  'separating_naip_flights', \n",
    "                  'SB_coastal_buffer', \n",
    "                  'SB_coastal_buffer.shp')\n",
    "coast = gpd.read_file(fp)\n",
    "coast_geo = coast.geometry.apply(mapping)\n",
    "\n",
    "# **************************************************************\n",
    "# load pre-trained random forest classifier\n",
    "rfc = load(prefix+'_rfc.joblib') \n",
    "\n",
    "# **************************************************************\n",
    "# select the scene ids from given year that intersect the coastal buffer\n",
    "# the itemids of all scenes that intersect the coast were previously stored in a csv\n",
    "# scene_ids = pd.read_csv(os.path.join(os.getcwd(),\n",
    "#                                      'separating_naip_flights',\n",
    "#                                      'coastal_scenes_ids.csv'))\n",
    "# scene_ids = scene_ids.loc[scene_ids['year'] == year]\n",
    "# scene_ids = scene_ids.reset_index().itemid\n",
    "\n",
    "#scene_ids = ['ca_m_3412037_nw_10_060_20200607',\n",
    "             # 'ca_m_3412039_nw_10_060_20200522',\n",
    "             # 'ca_m_3412040_ne_10_060_20200522',\n",
    "             # 'ca_m_3411934_sw_11_060_20200521',\n",
    "             # 'ca_m_3411936_se_11_060_20200521']\n",
    "\n",
    "scene_ids = ['ca_m_3411935_se_11_060_20200521']\n",
    "\n",
    "# **************************************************************\n",
    "# prepare folder to save rasters\n",
    "if save_rasters:\n",
    "    fp = os.path.join(os.getcwd(), 'processing_results')\n",
    "    if os.path.exists(fp) == False:\n",
    "        os.mkdir(fp)\n",
    "    if filter_rasters:\n",
    "        fp = os.path.join(fp, prefix+'_filter_clip_preds_' + str(year))\n",
    "    else:\n",
    "        fp = os.path.join(fp, prefix+'_clip_preds_' + str(year))\n",
    "    if os.path.exists(fp) == False:\n",
    "        os.mkdir(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14ae5874-c1cc-448f-a600-a221b2faf362",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-65af0f0b-9d06-11ed-8a5f-2aa2ba8adfa1</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_gateway.GatewayCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.e3268597c1f3453ebc74b4a64cb01c56/status\" target=\"_blank\">https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.e3268597c1f3453ebc74b4a64cb01c56/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div style='background-color: #f2f2f2; display: inline-block; padding: 10px; border: 1px solid #999999;'>\n",
       "  <h3>GatewayCluster</h3>\n",
       "  <ul>\n",
       "    <li><b>Name: </b>prod.e3268597c1f3453ebc74b4a64cb01c56\n",
       "    <li><b>Dashboard: </b><a href='https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.e3268597c1f3453ebc74b4a64cb01c56/status' target='_blank'>https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.e3268597c1f3453ebc74b4a64cb01c56/status</a>\n",
       "  </ul>\n",
       "</div>\n",
       "\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://10.244.60.10:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize DASK cluster\n",
    "cluster = dask_gateway.GatewayCluster()\n",
    "cluster.scale(15)\n",
    "\n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9abca9e7-fddb-4341-8257-2552c9e0a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# collect processing information for each scene\n",
    "times_pre = []\n",
    "times_class = []\n",
    "times_post = []\n",
    "processed = []\n",
    "reason = []\n",
    "veg_pixels = [] # number of pixels with ndwi<0.3 and ndwi>0.05\n",
    "n_pixels = []   # number of non-zero pixels in masked scene\n",
    "\n",
    "# parameters for GLCM \n",
    "distances = [1]     \n",
    "angles = [np.pi/2] # North\n",
    "\n",
    "# counter for scenes queued for processing\n",
    "N = len(scene_ids)\n",
    "t_total = time.time()\n",
    "\n",
    "# ---------------------------------------\n",
    "# ---------------------------------------\n",
    "\n",
    "for itemid in scene_ids:\n",
    "    t_alpha = time.time()\n",
    "    \n",
    "    # ***********************************************************************************************\n",
    "    # *************************************** PRE-PROCESSING ****************************************\n",
    "    # open NAIP scene and clip to coast\n",
    "    t0 = time.time()\n",
    "    raster = rf.rioxr_from_itemid(itemid).rio.clip(coast_geo, coast.crs)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # select pixels with data (blacked out portions have 0 on all bands)\n",
    "    df = rf.raster_as_df(raster.to_numpy(), ['r','g','b','nir'])\n",
    "    df = df.loc[ (df['nir'] != 0) | (df['r'] != 0) | (df['g'] != 0) | (df['b'] != 0)]\n",
    "    n_pixels.append(df.shape[0])\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # stop if there's no data at intersection\n",
    "    if df.shape[0] == 0:\n",
    "        rf.finish_processing('no_data', processed, reason, times_pre, times_class, times_post, veg_pixels, itemid)\n",
    "        if verbose:\n",
    "            rf.finish_processing_message('no_data', itemid)\n",
    "\n",
    "    else:\n",
    "        # find vegetation pixels to go into model\n",
    "        # keep ndices of water and low-ndvi pixels\n",
    "        # add ndvi and ndwi features for each pixel\n",
    "        t0 = time.time()\n",
    "        is_veg, water_index, not_veg_index = rf.add_spectral_features(df, \n",
    "                                                                      ndwi_thresh = 0.3, \n",
    "                                                                      ndvi_thresh = 0.05) \n",
    "      # ---------------------------------------\n",
    "        # stop if there are no vegetation pixels at intersection\n",
    "        if is_veg.shape[0] == 0:\n",
    "            rf.finish_processing('no_veg', processed, reason, times_pre, times_class, times_post, veg_pixels, itemid)            \n",
    "            if verbose:\n",
    "                rf.finish_processing_message('no_veg', itemid)\n",
    "\n",
    "        else:\n",
    "            processed.append('Y')\n",
    "            reason.append('processed')  \n",
    "            \n",
    "            # ---------------------------------------\n",
    "            # discard ndwi and add date features\n",
    "            is_veg.drop('ndwi', axis=1, inplace=True)\n",
    "            is_veg = rf.add_date_features(is_veg, rf.rioxr_from_itemid(itemid).datetime)\n",
    "\n",
    "\n",
    "    # *************************************************************************************************\n",
    "    # ******************************** CREATE R,G,B,NIR AUXILIARY RASTERS *****************************\n",
    "            t0 = time.time()\n",
    "            # make auxiliary spectral rasters from clipped NAIP \n",
    "            band_names = ['r_', 'g_', 'b_', 'nir_']\n",
    "            tags = ['_avgs', '_entrs']\n",
    "            window_fps = []\n",
    "            window_cols = []\n",
    "\n",
    "            for name, band in zip(band_names,range(1,5)):\n",
    "                rast_name = name+itemid\n",
    "                sr.avg_raster(raster=raster, band=band, rast_name=rast_name, n=3)\n",
    "                sr.entropy_raster(raster=raster, band=band, rast_name=rast_name, n=window_r)\n",
    "\n",
    "                for tag in tags:\n",
    "                    window_fps.append(os.path.join(os.getcwd(), 'temp', rast_name + tag + '.tif'))        \n",
    "                    window_cols.append( name.replace('_','')+tag.replace('s',''))\n",
    "            # print('created R,G,B,NIR auxiliary rasters (avgs,entr)', time.time()-t0)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79599f1-7874-4ba7-b168-64965d8fe5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1409, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "2023-01-25 23:37:35,815 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m                 glcm \u001b[38;5;241m=\u001b[39m graycomatrix(window[band_n], distances\u001b[38;5;241m=\u001b[39mdistances, angles\u001b[38;5;241m=\u001b[39mangles) \u001b[38;5;66;03m# assuming 1 distance and 1 angle\u001b[39;00m\n\u001b[1;32m     18\u001b[0m                 contrast[y,x] \u001b[38;5;241m=\u001b[39m graycoprops(glcm, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontrast\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 19\u001b[0m                 correlation[y,x] \u001b[38;5;241m=\u001b[39m \u001b[43mgraycoprops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglcm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcorrelation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     21\u001b[0m sr\u001b[38;5;241m.\u001b[39msave_raster_checkpoints(contrast, crs\u001b[38;5;241m=\u001b[39mraster\u001b[38;5;241m.\u001b[39mrio\u001b[38;5;241m.\u001b[39mcrs, transf\u001b[38;5;241m=\u001b[39mraster\u001b[38;5;241m.\u001b[39mrio\u001b[38;5;241m.\u001b[39mtransform(), rast_name\u001b[38;5;241m=\u001b[39mband_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontrast\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m sr\u001b[38;5;241m.\u001b[39msave_raster_checkpoints(correlation, crs\u001b[38;5;241m=\u001b[39mraster\u001b[38;5;241m.\u001b[39mrio\u001b[38;5;241m.\u001b[39mcrs, transf\u001b[38;5;241m=\u001b[39mraster\u001b[38;5;241m.\u001b[39mrio\u001b[38;5;241m.\u001b[39mtransform(), rast_name\u001b[38;5;241m=\u001b[39mband_name\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrelation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/skimage/feature/texture.py:259\u001b[0m, in \u001b[0;36mgraycoprops\u001b[0;34m(P, prop)\u001b[0m\n\u001b[1;32m    257\u001b[0m I \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mrange\u001b[39m(num_level))\u001b[38;5;241m.\u001b[39mreshape((num_level, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    258\u001b[0m J \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mrange\u001b[39m(num_level))\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, num_level, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 259\u001b[0m diff_i \u001b[38;5;241m=\u001b[39m I \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m diff_j \u001b[38;5;241m=\u001b[39m J \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39msum(J \u001b[38;5;241m*\u001b[39m P, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    262\u001b[0m std_i \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msum(P \u001b[38;5;241m*\u001b[39m (diff_i) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n",
      "File \u001b[0;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# *************************************************************************************\n",
    "# ******************************** CREATE TEXTURE RASTERS *****************************            \n",
    "y_len = raster.shape[1]\n",
    "x_len = raster.shape[2]\n",
    "for band_n, band_name in zip(range(4),band_names):\n",
    "    if band_n != 1:  # no texture features for Green band    \n",
    "        contrast = np.zeros((y_len,x_len))\n",
    "        correlation = np.zeros((y_len,x_len))\n",
    "\n",
    "        for y in range(y_len):\n",
    "            for x in range(x_len):\n",
    "                window = raster[:, y-window_r:y+window_r+1, x-window_r:x+window_r+1]\n",
    "                if (window.shape[1] != 2*window_r+1) | (window.shape[2] != 2*window_r+1):\n",
    "                    contrast[y,x] = np.nan\n",
    "                    correlation[y,x] = np.nan                                \n",
    "                else:\n",
    "                        glcm = graycomatrix(window[band_n], distances=distances, angles=angles) # assuming 1 distance and 1 angle\n",
    "                        contrast[y,x] = graycoprops(glcm, 'contrast')[0,0]\n",
    "                        correlation[y,x] = graycoprops(glcm, 'correlation')[0,0]\n",
    "\n",
    "        sr.save_raster_checkpoints(contrast, crs=raster.rio.crs, transf=raster.rio.transform(), rast_name=band_name+'contrast')\n",
    "        sr.save_raster_checkpoints(correlation, crs=raster.rio.crs, transf=raster.rio.transform(), rast_name=band_name+'correlation')\n",
    "\n",
    "        window_fps.append(os.path.join(os.getcwd(), 'temp',band_name + 'contrast.tif')) \n",
    "        window_fps.append(os.path.join(os.getcwd(), 'temp',band_name + 'correlation.tif')) \n",
    "\n",
    "        window_cols = window_cols + [band_name+'cont', band_name+'corr']\n",
    "\n",
    "del contrast, correlation\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ca31ef9-0f72-4d56-9761-44dbad293395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55714550"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/dask_gateway/client.py:1014: RuntimeWarning: coroutine 'rpc.close_rpc' was never awaited\n",
      "  self.scheduler_comm.close_rpc()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "2023-01-26 00:28:20,895 - distributed.client - ERROR - Exception raised while shutting down cluster prod.e3268597c1f3453ebc74b4a64cb01c56\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/dask_gateway/client.py\", line 993, in _stop_internal\n",
      "    await self.gateway._stop_cluster(self.name)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/dask_gateway/client.py\", line 654, in _stop_cluster\n",
      "    await self._request(\"DELETE\", url)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/dask_gateway/client.py\", line 397, in _request\n",
      "    resp = await session.request(method, url, json=json, **self._request_kwargs)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/aiohttp/client.py\", line 535, in _request\n",
      "    conn = await self._connector.connect(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/aiohttp/connector.py\", line 542, in connect\n",
      "    proto = await self._create_connection(req, traces, timeout)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/aiohttp/connector.py\", line 907, in _create_connection\n",
      "    _, proto = await self._create_direct_connection(req, traces, timeout)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/aiohttp/connector.py\", line 1154, in _create_direct_connection\n",
      "    hosts = await asyncio.shield(host_resolved)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/aiohttp/connector.py\", line 880, in _resolve_host\n",
      "    addrs = await self._resolver.resolve(host, port, family=self._family)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/aiohttp/resolver.py\", line 33, in resolve\n",
      "    infos = await self._loop.getaddrinfo(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/base_events.py\", line 860, in getaddrinfo\n",
      "    return await self.run_in_executor(\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/base_events.py\", line 818, in run_in_executor\n",
      "    executor.submit(func, *args), loop=self)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/concurrent/futures/thread.py\", line 167, in submit\n",
      "    raise RuntimeError('cannot schedule new futures after shutdown')\n",
      "RuntimeError: cannot schedule new futures after shutdown\n"
     ]
    }
   ],
   "source": [
    "x_len*y_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fac5ff89-1eb5-4f55-ade8-fdef97edb9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5281"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a7ec33f-46d2-4fc2-8143-0239bb8a554c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3277583864.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [7], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    y_len = raster.shape[1]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "    # *******************************************************************************************\n",
    "    # *********************** EXTRACT FEATURES FROM AUXILIARY RASTERS ***************************\n",
    "            window_values = []    \n",
    "            for fp_aux in window_fps:\n",
    "                match = rioxr.open_rasterio(fp_aux).squeeze()\n",
    "                match_vector = match.to_numpy().reshape(match.shape[0]*match.shape[1])\n",
    "                window_values.append(match_vector)\n",
    "                os.remove(fp_aux)\n",
    "\n",
    "            df_window = pd.DataFrame(dict(zip( window_cols, window_values)))\n",
    "\n",
    "            scene_features = pd.concat([is_veg, df_window.iloc[is_veg.index]], axis=1)\n",
    "\n",
    "    # **********************************************************************************************\n",
    "    # *************** REMOVE NA VALUES (PIXELS AT EDGE OF CLIPPED PART OF RASTER) ******************\n",
    "           # remove these indices from scene_features\n",
    "            # no need to add them anywhere else, they will be part of the raster's background\n",
    "            remove = scene_features[scene_features.r_cont.isna() == True].index\n",
    "            scene_features = scene_features.drop(remove)\n",
    "\n",
    "            #free memory            \n",
    "            del df_window, window_values, match_vector, match, remove\n",
    "            gc.collect()\n",
    "            \n",
    "            times_pre.append(time.time()-t0)\n",
    "       \n",
    "    # ******************************************************************************\n",
    "    # ******************************** ORDER FEATURES ****************************** \n",
    "\n",
    "            feature_order = [\n",
    "                         'r', 'r_avg', 'r_entr','r_cont', 'r_corr', \n",
    "                         'g', 'g_avg', 'g_entr',\n",
    "                         'b', 'b_avg', 'b_entr','b_cont', 'b_corr', \n",
    "                         'nir', 'nir_avg', 'nir_entr','nir_cont', 'nir_corr', \n",
    "                         'month', 'day_in_year'] # date\n",
    "\n",
    "            scene_features = scene_features[feature_order]\n",
    "            # print('finished assembling features')\n",
    "\n",
    "\n",
    "    # ***********************************************************************************************\n",
    "    # *************************************** CLASSIFICATION ****************************************\n",
    "            # convert into dask.array and predict using model\n",
    "            da_pixels = da.from_array(np.array(scene_features), chunks=728802)\n",
    "            scene_preds = rfc.predict(da_pixels)\n",
    "            \n",
    "            # ---------------------------------------\n",
    "            t0 = time.time()\n",
    "            preds = scene_preds.compute()\n",
    "            times_class.append(time.time() - t0)\n",
    "            # print('finished classification')\n",
    "\n",
    "    # ************************************************************************************************\n",
    "    # *************************************** POST-PROCESSING ****************************************\n",
    "            # recover pixel indices for iceplant classifications\n",
    "            t0 = time.time()\n",
    "            preds_df = pd.DataFrame(preds, \n",
    "                                 columns=['is_iceplant'], \n",
    "                                 index = scene_features.index)\n",
    "            is_iceplant_index = preds_df[preds_df.is_iceplant == 1].index.to_numpy()\n",
    "            non_iceplant_index = preds_df[preds_df.is_iceplant == 0].index.to_numpy()\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # reconstruct indices into image\n",
    "            indices = [non_iceplant_index,\n",
    "                       is_iceplant_index, \n",
    "                       not_veg_index,\n",
    "                       water_index]\n",
    "            values = [0,    # values assigned to pixels from each index\n",
    "                      1,\n",
    "                      2,\n",
    "                      3]\n",
    "            reconstruct = rf.indices_to_image(raster.shape[1], raster.shape[2], indices, values, back_value=100)\n",
    "            \n",
    "            # ---------------------------------------\n",
    "            # apply median 3x3 filter if needed\n",
    "            if filter:\n",
    "                reconstruct = median_filter(reconstruct, size=3)\n",
    "            \n",
    "            times_post.append(time.time() - t0)\n",
    "            # print('finished post-processing')\n",
    "\n",
    "    # ************************************************************************************************\n",
    "    # *************************************** SAVE RASTERS *******************************************  \n",
    "            if save_rasters:\n",
    "                if filter_rasters:\n",
    "                    filename = prefix+'_filter_clip_preds_' + itemid + '.tif'\n",
    "                else:\n",
    "                    filename = prefix+'_clip_preds_' + itemid + '.tif'\n",
    "                \n",
    "                with rasterio.open(\n",
    "                    os.path.join(fp, filename),  # file path\n",
    "                    'w',           # w = write\n",
    "                    driver = 'GTiff', # format\n",
    "                    height = reconstruct.shape[0], \n",
    "                    width = reconstruct.shape[1],\n",
    "                    count = 1,  # number of raster bands in the dataset\n",
    "                    dtype = rasterio.uint8,\n",
    "                    crs = raster.rio.crs,\n",
    "                    transform = raster.rio.transform(),\n",
    "                ) as dst:\n",
    "                    dst.write(reconstruct.astype(rasterio.uint8), 1)\n",
    "                    \n",
    "            if verbose:\n",
    "                print('FINISHED: ', itemid)        \n",
    "                \n",
    "\n",
    "    # ************************************************************************************************\n",
    "    # ************************************ FINAL INFO MESSAGE ***************************************            \n",
    "    N = N-1        \n",
    "    if verbose:\n",
    "        print('REMAINING: ', N, 'scenes', '\\n')\n",
    "    else:\n",
    "        print('REMAINING: ', N, 'scenes', end=\"\\r\")\n",
    "    \n",
    "print('TOTAL TIME: ', (time.time() - t_total)/60, ' mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6061bc8d-246b-4ea3-af74-80ef03e50c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save times processed and itemids as dataframe\n",
    "D = { 'itemid': scene_ids,\n",
    "     'processed': processed,\n",
    "     'reason':reason,\n",
    "     'pre_times': times_pre,\n",
    "     'class_times' : times_class,\n",
    "     'post_times' : times_post, \n",
    "     'processed_pix' : n_pixels }\n",
    "processing_df = pd.DataFrame(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00459eff-86c8-4bef-91b8-a23cf09a2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_processing_times:\n",
    "    fp = os.path.join(os.getcwd(),'processing_results')\n",
    "    if os.path.exists(fp) == False:\n",
    "        os.mkdir(fp)\n",
    "\n",
    "\n",
    "    if filter_rasters:\n",
    "        filename = prefix+'_filter_clip_processing_results_' + str(year) + '.csv'\n",
    "    else:\n",
    "        filename = prefix+'_clip_processing_results_' + str(year) + '.csv'\n",
    "\n",
    "    processing_df.to_csv(os.path.join(fp, filename ), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88286d0a-f345-482c-ab07-6c5d8c4c64e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
