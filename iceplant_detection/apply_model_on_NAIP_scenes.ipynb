{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22271604-a3d1-4887-bb60-b519c6aad648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc   # garbage collector\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "import rioxarray as rioxr\n",
    "\n",
    "import dask_gateway\n",
    "import dask.array as da\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "# custom modules\n",
    "#import raster_to_features as rf\n",
    "import A_data_sampling_workflow.sample_rasters as sr\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ee69c2-cbeb-4d7c-8907-a49931a06e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year for which to predict iceplant locations\n",
    "year = 2020\n",
    "\n",
    "# whether to apply median filter to raster\n",
    "filter_rasters = False\n",
    "filter_side = 5\n",
    "\n",
    "# whether to save rasters\n",
    "save_rasters = True\n",
    "prefix = 'salt13_p30'\n",
    "\n",
    "# whether to print processing info at runtime\n",
    "verbose = True\n",
    "\n",
    "save_processing_times = True\n",
    "\n",
    "delete_aux_rasters = True\n",
    "\n",
    "# **************************************************************\n",
    "clip = True\n",
    "\n",
    "# **************************************************************\n",
    "# whether only to process aois\n",
    "only_aois = False\n",
    "\n",
    "# **************************************************************\n",
    "uses_ndvi = True\n",
    "\n",
    "# **************************************************************\n",
    "# radius of the disk (in pixels) over which entropy is calculated\n",
    "entropy_r = 6\n",
    "\n",
    "# features for snow13\n",
    "feature_order = ['r', 'r_avg13', 'r_entr13', \n",
    "                 'g', 'g_avg13', 'g_entr13', \n",
    "                 'b', 'b_avg13', 'b_entr13', \n",
    "                 'nir', 'nir_avg13', 'nir_entr13', \n",
    "                 'ndvi', 'ndvi_avg13', 'ndvi_entr13', \n",
    "                 'month', 'day_in_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b6fc66-a393-4f8d-96e4-f75a9b77104e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# length of side of the square window over which average/max/min are calculated.\n",
    "box_side = entropy_r *2 +1\n",
    "\n",
    "# **************************************************************\n",
    "# open shapefile of SB coastal buffer and process it to use it for clipping\n",
    "fp = os.path.join(os.getcwd(), \n",
    "                  'separating_naip_flights', \n",
    "                  'SB_coastal_buffer', \n",
    "                  'SB_coastal_buffer.shp')\n",
    "coast = gpd.read_file(fp)\n",
    "coast_geo = coast.geometry.apply(mapping)\n",
    "\n",
    "# **************************************************************\n",
    "# load pre-trained random forest classifier\n",
    "rfc = load(prefix+'_rfc.joblib') \n",
    "\n",
    "# **************************************************************\n",
    "\n",
    "if only_aois:\n",
    "    scene_ids = ['ca_m_3412037_nw_10_060_20200607',\n",
    "                 'ca_m_3412039_nw_10_060_20200522',\n",
    "                 'ca_m_3412040_ne_10_060_20200522',\n",
    "                 'ca_m_3411934_sw_11_060_20200521',\n",
    "                 'ca_m_3411936_se_11_060_20200521']\n",
    "else:    \n",
    "    # select the scene ids from given year that intersect the coastal buffer\n",
    "    # the itemids of all scenes that intersect the coast were previously stored in a csv\n",
    "    scene_ids = pd.read_csv(os.path.join(os.getcwd(),\n",
    "                                         'separating_naip_flights',\n",
    "                                         'coastal_scenes_ids.csv'))\n",
    "    scene_ids = scene_ids.loc[scene_ids['year'] == year]\n",
    "    scene_ids = scene_ids.reset_index().itemid\n",
    "\n",
    "# **************************************************************\n",
    "# prepare folder to save rasters\n",
    "if save_rasters:\n",
    "    fp = os.path.join(os.getcwd(), 'processing_results')\n",
    "    if os.path.exists(fp) == False:\n",
    "        os.mkdir(fp)\n",
    "    if filter_rasters:\n",
    "        fp = os.path.join(fp, prefix+'_filter_clip_preds_' + str(year))\n",
    "    else:\n",
    "        fp = os.path.join(fp, prefix+'_clip_preds_' + str(year))\n",
    "    if os.path.exists(fp) == False:\n",
    "        os.mkdir(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ae5874-c1cc-448f-a600-a221b2faf362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # initialize DASK cluster\n",
    "# cluster = dask_gateway.GatewayCluster()\n",
    "# cluster.scale(15)\n",
    "\n",
    "# client = cluster.get_client()\n",
    "# client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307353a-4d65-486c-9c39-fc7fd36fb67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected data on scene 24.580111980438232\n",
      "selected vegetation pixels 3.2729015350341797\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr) 468.1312906742096\n",
      "created/verified NDVI auxiliary rasters (avgs,entr) 108.44607663154602\n",
      "finished assembling features\n",
      "finished classification\n",
      "finished post-processing\n",
      "FINISHED:  ca_m_3412037_nw_10_060_20200607\n",
      "REMAINING:  23 scenes \n",
      "\n",
      "selected data on scene 19.182246923446655\n",
      "selected vegetation pixels 1.9463961124420166\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr) 165.5145034790039\n",
      "created/verified NDVI auxiliary rasters (avgs,entr) 34.99815011024475\n",
      "finished assembling features\n",
      "finished classification\n",
      "finished post-processing\n",
      "FINISHED:  ca_m_3412037_ne_10_060_20200607\n",
      "REMAINING:  22 scenes \n",
      "\n",
      "selected data on scene 14.23858380317688\n",
      "selected vegetation pixels 0.4023923873901367\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr) 74.90145444869995\n",
      "created/verified NDVI auxiliary rasters (avgs,entr) 17.215584754943848\n",
      "finished assembling features\n",
      "finished classification\n",
      "finished post-processing\n",
      "FINISHED:  ca_m_3412029_sw_10_060_20200607\n",
      "REMAINING:  21 scenes \n",
      "\n",
      "no data at intersection of scene with coastal buffer\n",
      "FINISHED:  ca_m_3412004_sw_10_060_20200607 \n",
      "REMAINING:  20 scenes \n",
      "\n",
      "no data at intersection of scene with coastal buffer\n",
      "FINISHED:  ca_m_3412003_se_10_060_20200607 \n",
      "REMAINING:  19 scenes \n",
      "\n",
      "selected data on scene 14.220940828323364\n",
      "selected vegetation pixels 0.17566990852355957\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr) 91.70502519607544\n",
      "created/verified NDVI auxiliary rasters (avgs,entr) 22.521557331085205\n",
      "finished assembling features\n",
      "finished classification\n",
      "finished post-processing\n",
      "FINISHED:  ca_m_3412003_ne_10_060_20200607\n",
      "REMAINING:  18 scenes \n",
      "\n",
      "selected data on scene 20.653401851654053\n",
      "selected vegetation pixels 1.9367363452911377\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr) 190.42996191978455\n",
      "created/verified NDVI auxiliary rasters (avgs,entr) 42.902398347854614\n",
      "finished assembling features\n",
      "finished classification\n",
      "finished post-processing\n",
      "FINISHED:  ca_m_3412038_nw_10_060_20200523\n",
      "REMAINING:  17 scenes \n",
      "\n",
      "selected data on scene 18.43400001525879\n",
      "selected vegetation pixels 2.0757718086242676\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr) 183.79718804359436\n",
      "created/verified NDVI auxiliary rasters (avgs,entr) 40.86392259597778\n",
      "finished assembling features\n",
      "finished classification\n",
      "finished post-processing\n",
      "FINISHED:  ca_m_3412040_nw_10_060_20200522\n",
      "REMAINING:  16 scenes \n",
      "\n",
      "selected data on scene 18.711997985839844\n",
      "selected vegetation pixels 2.005216598510742\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr) 164.051922082901\n",
      "created/verified NDVI auxiliary rasters (avgs,entr) 35.38433074951172\n",
      "finished assembling features\n",
      "finished classification\n",
      "finished post-processing\n",
      "FINISHED:  ca_m_3412040_ne_10_060_20200522\n",
      "REMAINING:  15 scenes \n",
      "\n",
      "selected data on scene 18.274120569229126\n",
      "selected vegetation pixels 1.9199390411376953\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr) 139.4366376399994\n",
      "created/verified NDVI auxiliary rasters (avgs,entr) 30.163299322128296\n",
      "finished assembling features\n",
      "finished classification\n",
      "finished post-processing\n",
      "FINISHED:  ca_m_3412039_nw_10_060_20200522\n",
      "REMAINING:  14 scenes \n",
      "\n",
      "selected data on scene 19.722073554992676\n",
      "selected vegetation pixels 1.9967458248138428\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr) 144.56444907188416\n",
      "created/verified NDVI auxiliary rasters (avgs,entr) 31.054309844970703\n",
      "finished assembling features\n",
      "finished classification\n",
      "finished post-processing\n",
      "FINISHED:  ca_m_3412039_ne_10_060_20200522\n",
      "REMAINING:  13 scenes \n",
      "\n",
      "selected data on scene 19.68744134902954\n",
      "selected vegetation pixels 1.930107593536377\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr) 154.34116220474243\n",
      "created/verified NDVI auxiliary rasters (avgs,entr) 33.20129418373108\n",
      "finished assembling features\n",
      "finished classification\n",
      "finished post-processing\n",
      "FINISHED:  ca_m_3412038_ne_10_060_20200522\n",
      "REMAINING:  12 scenes \n",
      "\n",
      "selected data on scene 21.849520921707153\n",
      "selected vegetation pixels 2.02243971824646\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr) 295.5486183166504\n",
      "created/verified NDVI auxiliary rasters (avgs,entr) 69.25643420219421\n",
      "finished assembling features\n",
      "finished classification\n",
      "finished post-processing\n",
      "FINISHED:  ca_m_3411933_nw_11_060_20200522\n",
      "REMAINING:  11 scenes \n",
      "\n",
      "selected data on scene 18.058578491210938\n",
      "selected vegetation pixels 0.5228621959686279\n",
      "created/verified R,G,B,NIR auxiliary rasters (avgs, entr) 54.0833055973053\n",
      "created/verified NDVI auxiliary rasters (avgs,entr) 11.381625652313232\n",
      "finished assembling features\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# collect processing information for each scene\n",
    "times_pre = []\n",
    "times_class = []\n",
    "times_post = []\n",
    "processed = []\n",
    "reason = []\n",
    "veg_pixels = [] # number of pixels with ndwi<0.3 and ndwi>0.05\n",
    "n_pixels = []   # number of non-zero pixels in masked scene\n",
    "\n",
    "# counter for scenes queued for processing\n",
    "N = len(scene_ids)\n",
    "t_total = time.time()\n",
    "\n",
    "# ---------------------------------------\n",
    "# ---------------------------------------\n",
    "\n",
    "for itemid in scene_ids:    \n",
    "    # ***********************************************************************************************\n",
    "    # *************************************** PRE-PROCESSING ****************************************\n",
    "    # open NAIP scene and clip to coast\n",
    "    t0 = time.time()\n",
    "\n",
    "    raster = sr.rioxr_from_itemid(itemid)\n",
    "    if clip:\n",
    "        raster = raster.rio.clip(coast_geo, coast.crs)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # select pixels with data (blacked out portions have 0 on all bands)\n",
    "    df = sr.raster_as_df(raster.to_numpy(), ['r','g','b','nir'])\n",
    "    df = df.loc[ (df['nir'] != 0) | (df['r'] != 0) | (df['g'] != 0) | (df['b'] != 0)]\n",
    "    n_pixels.append(df.shape[0])\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # stop if there's no data at intersection\n",
    "    if df.shape[0] == 0:\n",
    "        sr.finish_processing('no_data', processed, reason, times_pre, times_class, times_post, veg_pixels, itemid)\n",
    "        if verbose:\n",
    "            sr.finish_processing_message('no_data', itemid)\n",
    "\n",
    "    else:\n",
    "        # find vegetation pixels to go into model\n",
    "        # keep indices of water and low-ndvi pixels\n",
    "        # add ndvi and ndwi features for each pixel\n",
    "        if verbose:\n",
    "            print('selected data on scene', time.time()-t0)\n",
    "        t0 = time.time()\n",
    "        is_veg, water_index, not_veg_index = sr.add_spectral_features(df, \n",
    "                                                                      ndwi_thresh = 0.3, \n",
    "                                                                      ndvi_thresh = 0.05) \n",
    "      # ---------------------------------------\n",
    "        # stop if there are no vegetation pixels at intersection\n",
    "        if is_veg.shape[0] == 0:\n",
    "            sr.finish_processing('no_veg', processed, reason, times_pre, times_class, times_post, veg_pixels, itemid)            \n",
    "            if verbose:\n",
    "                sr.finish_processing_message('no_veg', itemid)\n",
    "\n",
    "        else:\n",
    "            processed.append('Y')\n",
    "            reason.append('processed')\n",
    "            if verbose:\n",
    "                print('selected vegetation pixels', time.time()-t0)\n",
    "            \n",
    "            # ---------------------------------------\n",
    "            # discard ndwi and add date features\n",
    "            is_veg.drop('ndwi', axis=1, inplace=True)\n",
    "            is_veg = sr.add_date_features(is_veg, sr.rioxr_from_itemid(itemid).datetime)\n",
    "\n",
    "\n",
    "    # *************************************************************************************************\n",
    "    # ******************************** CREATE R,G,B,NIR AUXILIARY RASTERS *****************************\n",
    "            t0 = time.time()\n",
    "            # make auxiliary spectral rasters from clipped NAIP \n",
    "            band_names = ['r_', 'g_', 'b_', 'nir_']\n",
    "            tags = ['_avgs', '_entrs']\n",
    "            window_fps = []\n",
    "            window_cols = []\n",
    "\n",
    "            for name, band in zip(band_names,range(1,5)):\n",
    "                rast_name = name+itemid\n",
    "                \n",
    "                for tag in tags:\n",
    "                    rast_fp = os.path.join(os.getcwd(), 'temp', rast_name + tag + '.tif')\n",
    "                    window_fps.append(rast_fp)        \n",
    "                    window_cols.append( name.replace('_','')+tag.replace('s',str(box_side)))\n",
    "                    \n",
    "                    if os.path.isfile(rast_fp) == False:\n",
    "                        if tag == '_avgs':\n",
    "                            sr.avg_raster(raster=raster, band=band, rast_name=rast_name, n=box_side)                            \n",
    "                        elif tag == '_entrs':\n",
    "                            sr.entropy_raster(raster=raster, band=band, rast_name=rast_name, n=entropy_r)\n",
    "                \n",
    "            if verbose:\n",
    "                print('created/verified R,G,B,NIR auxiliary rasters (avgs, entr)', time.time()-t0)\n",
    "\n",
    "\n",
    "    # ********************************************************************************************\n",
    "    # ******************************** CREATE NDVI AUXILIARY RASTERS *****************************\n",
    "            if uses_ndvi:\n",
    "                t0 = time.time()\n",
    "                # make auxiliary NDVI from clipped NAIP \n",
    "                ndvi = sr.ndvi_xarray(raster)\n",
    "                band_names.append('ndvi_')\n",
    "                rast_name = 'ndvi_'+itemid\n",
    "                \n",
    "                for tag in tags:\n",
    "                    rast_fp = os.path.join(os.getcwd(), 'temp', rast_name + tag + '.tif')\n",
    "                    window_fps.append(rast_fp)        \n",
    "                    window_cols.append('ndvi' + tag.replace('s',str(box_side)))                \n",
    "                    \n",
    "                    if os.path.isfile(rast_fp) == False:\n",
    "                        if tag == '_avgs':\n",
    "                            sr.avg_raster(rast_data=ndvi, \n",
    "                                          crs=raster.rio.crs, \n",
    "                                          transf=raster.rio.transform(), \n",
    "                                          rast_name=rast_name, \n",
    "                                          n=box_side)\n",
    "                        elif tag == '_entrs':\n",
    "                            # adjusting to entropy input types\n",
    "                            ndvi = ndvi*100+100  \n",
    "                            sr.entropy_raster(rast_data=ndvi.astype('uint8'), \n",
    "                                              crs=raster.rio.crs, \n",
    "                                              transf=raster.rio.transform(), \n",
    "                                              rast_name=rast_name, \n",
    "                                              n=entropy_r)\n",
    "                if verbose:\n",
    "                    print('created/verified NDVI auxiliary rasters (avgs,entr)', time.time()-t0)\n",
    "                #free memory\n",
    "                del ndvi\n",
    "                gc.collect()\n",
    "\n",
    "\n",
    "    # *******************************************************************************************\n",
    "    # *********************** EXTRACT FEATURES FROM AUXILIARY RASTERS ***************************\n",
    "            window_values = []    \n",
    "            for fp_aux in window_fps:\n",
    "                match = rioxr.open_rasterio(fp_aux).squeeze()\n",
    "                match_vector = match.to_numpy().reshape(match.shape[0]*match.shape[1])\n",
    "                window_values.append(match_vector)\n",
    "                if delete_aux_rasters:\n",
    "                    os.remove(fp_aux)\n",
    "\n",
    "            df_window = pd.DataFrame(dict(zip( window_cols, window_values)))\n",
    "\n",
    "            scene_features = pd.concat([is_veg, df_window.iloc[is_veg.index]], axis=1)\n",
    "\n",
    "            # **********************************************************************************************\n",
    "            # *************** REMOVE NA VALUES (PIXELS AT EDGE OF CLIPPED PART OF RASTER) ******************\n",
    "            # combine indices for r_min == 0 and ndvi_min == nan, ndvi_avg == nan\n",
    "\n",
    "            # **** THIS NEEDS TO BE NOT HARDCODED: r_min11 and ndvi_min11 ****\n",
    "            remove = set()\n",
    "            if '_min' in tags:\n",
    "                remove = scene_features.r_min11[scene_features.r_min11 == 0].index\n",
    "            if uses_ndvi:\n",
    "                for band in [x.replace('s',str(box_side)) for x in ['ndvi'+ y for y in tags]]:\n",
    "                    remove = remove.union(scene_features[band][scene_features[band].isna() == True].index)\n",
    "            # remove these indices from scene_features\n",
    "            # no need to add them anywhere else, they will be part of the raster's background\n",
    "            scene_features = scene_features.drop(remove)\n",
    "\n",
    "            #free memory            \n",
    "            del df_window, window_values, match_vector, match, remove\n",
    "            gc.collect()  \n",
    "\n",
    "            times_pre.append(time.time()-t0)\n",
    "\n",
    "            # ******************************************************************************\n",
    "            # ******************************** ORDER FEATURES ****************************** \n",
    "\n",
    "            scene_features = scene_features[feature_order]\n",
    "            if verbose:\n",
    "                print('finished assembling features')\n",
    "\n",
    "            # ***********************************************************************************************\n",
    "            # *************************************** CLASSIFICATION ****************************************\n",
    "            # convert into dask.array and predict using model\n",
    "            #da_pixels = da.from_array(np.array(scene_features), chunks=728802)\n",
    "            da_pixels = np.array(scene_features)\n",
    "            scene_preds = rfc.predict(da_pixels)\n",
    "\n",
    "            # ---------------------------------------\n",
    "            t0 = time.time()\n",
    "            #preds = scene_preds.compute()\n",
    "            preds = scene_preds\n",
    "            times_class.append(time.time() - t0)\n",
    "            if verbose:\n",
    "                print('finished classification')\n",
    "\n",
    "            # ************************************************************************************************\n",
    "            # *************************************** POST-PROCESSING ****************************************\n",
    "            # recover pixel indices for iceplant classifications\n",
    "            t0 = time.time()\n",
    "            preds_df = pd.DataFrame(preds, \n",
    "                                 columns=['is_iceplant'], \n",
    "                                 index = scene_features.index)\n",
    "            is_iceplant_index = preds_df[preds_df.is_iceplant == 1].index.to_numpy()\n",
    "            non_iceplant_index = preds_df[preds_df.is_iceplant == 0].index.to_numpy()\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # reconstruct indices into image\n",
    "            indices = [non_iceplant_index,\n",
    "                       is_iceplant_index, \n",
    "                       not_veg_index,\n",
    "                       water_index]\n",
    "            values = [0,    # values assigned to pixels from each index\n",
    "                      1,\n",
    "                      2,\n",
    "                      3]\n",
    "            reconstruct = sr.indices_to_image(raster.shape[1], raster.shape[2], indices, values, back_value=100)\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # apply median 3x3 filter if needed\n",
    "            if filter:\n",
    "                reconstruct = median_filter(reconstruct, size=filter_side)\n",
    "\n",
    "            times_post.append(time.time() - t0)\n",
    "            if verbose:\n",
    "                print('finished post-processing')\n",
    "\n",
    "            # ************************************************************************************************\n",
    "            # *************************************** SAVE RASTERS *******************************************  \n",
    "            if save_rasters:\n",
    "                if filter_rasters:\n",
    "                    filename = prefix+'_filter_clip_preds_' + itemid + '.tif'\n",
    "                else:\n",
    "                    filename = prefix+'_clip_preds_' + itemid + '.tif'\n",
    "\n",
    "                with rasterio.open(\n",
    "                    os.path.join(fp, filename),  # file path\n",
    "                    'w',           # w = write\n",
    "                    driver = 'GTiff', # format\n",
    "                    height = reconstruct.shape[0], \n",
    "                    width = reconstruct.shape[1],\n",
    "                    count = 1,  # number of raster bands in the dataset\n",
    "                    dtype = rasterio.uint8,\n",
    "                    crs = raster.rio.crs,\n",
    "                    transform = raster.rio.transform(),\n",
    "                ) as dst:\n",
    "                    dst.write(reconstruct.astype(rasterio.uint8), 1)\n",
    "\n",
    "            if verbose:\n",
    "                print('FINISHED: ', itemid)        \n",
    "\n",
    "    # ***********************************************************************************************\n",
    "    # ************************************ FINAL INFO MESSAGE ***************************************            \n",
    "    N = N-1        \n",
    "    if verbose:\n",
    "        print('REMAINING: ', N, 'scenes', '\\n')\n",
    "    else:\n",
    "        print('REMAINING: ', N, 'scenes', end=\"\\r\")\n",
    "    \n",
    "print('TOTAL TIME: ', (time.time() - t_total)/60, ' mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061bc8d-246b-4ea3-af74-80ef03e50c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save times processed and itemids as dataframe\n",
    "D = { 'itemid': scene_ids,\n",
    "     'processed': processed,\n",
    "     'reason':reason,\n",
    "     'pre_times': times_pre,\n",
    "     'class_times' : times_class,\n",
    "     'post_times' : times_post, \n",
    "     'processed_pix' : n_pixels }\n",
    "processing_df = pd.DataFrame(D)\n",
    "processing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00459eff-86c8-4bef-91b8-a23cf09a2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_processing_times:\n",
    "    fp = os.path.join(os.getcwd(),'processing_results')\n",
    "    if os.path.exists(fp) == False:\n",
    "        os.mkdir(fp)\n",
    "\n",
    "\n",
    "    if filter_rasters:\n",
    "        filename = prefix+'_filter_clip_processing_results_' + str(year) + '.csv'\n",
    "    else:\n",
    "        filename = prefix+'_clip_processing_results_' + str(year) + '.csv'\n",
    "\n",
    "    processing_df.to_csv(os.path.join(fp, filename ), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88286d0a-f345-482c-ab07-6c5d8c4c64e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
