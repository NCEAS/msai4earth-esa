{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7857bfb-d31c-4c6b-937f-0f14b338b79c",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This notebook extracts spectral features of NAIP images at random points within polygons in the 'polygons_form_naip_images' folder. These polygons are known ice plant and non ice plant locations within a specific NAIP image. \n",
    "\n",
    "\n",
    "Once the aoi and years are specified, the notebook samples first polygons labeled as ice plant locations and then polygons labeled as non-ice plant locations. Two methods for sampling polygons are implemented in the `extracting_points_from_polygons,` and both are used in this notebook. The first one, `naip_sample_proportion`, samples a fixed fraction of the points in each polygon. The second one, `naip_sample_sliding`, samples a fixed fraction of the points in each polygon up to a maximum number of points. Polygons vary greatly in size, so simply sampling a fraction of the points in each polygon would result in an over-sampling of bigger polygons (most often those corresponding to non-ice plant locations), which in turn would unbalance the training set towards one label. The parameters used in this notebook were determined to obtain a final training set with a 3:1 proportion of non-ice plant to ice plant points. \n",
    "\n",
    "**NOTEBOOK VARIABLES:**\n",
    "\n",
    "- `aoi` (string): This is the area of interest from which the polygons we want to sample were collected. Must be one of the following: 'campus_lagoon','carpinteria','gaviota',or 'point_conception'. \n",
    "\n",
    "- `years` (array): can be any subset from [2012, 2014, 2016, 2018, 2020], except if aoi = 'point_conception'. If aoi = 'point_conception' then 2016 should not be included since there are not points to NAIP images to sample from on that year. \n",
    "\n",
    "- `sample_fraction` (float in (0,1]): fraction of points to sample from each polygon\n",
    "\n",
    "- `max_sample` (int): maximum number of points to sample from a polygon\n",
    "\n",
    "**OUTPUT:**\n",
    "\n",
    "The output is a dataframe of points with the following features:\n",
    "\n",
    "- geometry: coordinates of point *p* in the NAIP image's CRS\n",
    "- naip_id: itemid of the NAIP from which *p* was sampled from\n",
    "- polygon_id: id of the polygon from which *p* was sampled from\n",
    "- iceplant: whether point *p* corresponds to a confirmed iceplant location or a confirmed non-iceplant location (0 = non-iceplant, 1 = iceplant)\n",
    "- r, g, b, nir: Red, Green, Blue and NIR bands values of NAIP scene with naip_id at at cooridnates of point *p*\n",
    "\n",
    "The dataframe is then saved in the 'temp' folder as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21b9a0-c9a8-44fb-9f3f-b07fa5cf2a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "import extracting_points_from_polygons as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537b008-3fab-4251-94ad-177503dab258",
   "metadata": {},
   "source": [
    "# Specify AOI and years from which to sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a1d84e-4b5d-4606-aea2-a14747078dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# ************* NOTEBOOK VARIABLES ******************\n",
    "\n",
    "# aois = ['campus_lagoon','carpinteria','gaviota','point_conception']\n",
    "aoi = 'gaviota'\n",
    "\n",
    "# years = array of years, can be any subset from [2012, 2014, 2016, 2018, 2020]\n",
    "# except if aoi = 'point_conception' (no pts for 2016)\n",
    "years = [2016]\n",
    "\n",
    "# sample 90% of pts in each polygon\n",
    "sample_fraction = 0.9\n",
    "\n",
    "# maximum number of pts to sample in a polygon\n",
    "max_sample = 1500\n",
    "# ***************************************************\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2e2927-ee65-4084-9541-a6c69269f238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b192b4c-5bf5-470d-83e4-bf9b68669536",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pts = []\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    # open polygons\n",
    "    fp = pp.path_to_polygons(aoi,year)\n",
    "    polys = gpd.read_file(fp)\n",
    "    \n",
    "    polys_ice = polys.loc[polys.iceplant==1]\n",
    "    polys_ice.reset_index(inplace=True, drop=True)\n",
    "    # sample sample_fraction of pts in polygon\n",
    "    pts_ice = pp.naip_sample_proportion_no_warnings(polys_ice, \n",
    "                                                    polys.naip_id[0], \n",
    "                                                    sample_fraction)  \n",
    "\n",
    "    print('*** '+str(year)+' # ice plant pts sampled')\n",
    "    print(pts_ice.shape[0])\n",
    "    pts_ice.polygon_id.value_counts()\n",
    "\n",
    "    \n",
    "    polys_nonice = polys.loc[polys.iceplant==0]\n",
    "    polys_nonice.reset_index(inplace=True, drop=True)\n",
    "    # sample sample_fraction of pts in polygon, but at most max_sample points\n",
    "    pts_nonice = pp.naip_sample_sliding_no_warnings(polys_nonice, polys.naip_id[0], \n",
    "                                                    sample_fraction, \n",
    "                                                    max_sample)\n",
    "\n",
    "    print('*** '+str(year)+' # non ice plant pts sampled')\n",
    "    print(pts_nonice.shape[0])\n",
    "    pts_nonice.polygon_id.value_counts()\n",
    "    \n",
    "    pts = pd.concat([pts_ice,pts_nonice])\n",
    "    print('*** '+str(year)+' # proportions')\n",
    "    pp.iceplant_proportions(pts.iceplant)\n",
    "    \n",
    "    all_pts.append(pts)\n",
    "    \n",
    "    print( '---------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e34b7-9c91-41fc-9e75-c0ea8d513d03",
   "metadata": {},
   "source": [
    "# Save points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c950ba6-30b6-466b-ab19-1b3eccceaf9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(years)):\n",
    "    fp = os.path.join(os.getcwd(), \n",
    "                      'temp', \n",
    "                      aoi+'_points_'+str(year)+'.csv')\n",
    "    pts[i].to_csv(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3a2c6-fb1d-415b-bfa2-1bf568172045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
