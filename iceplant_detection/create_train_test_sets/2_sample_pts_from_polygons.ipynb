{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7857bfb-d31c-4c6b-937f-0f14b338b79c",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "This notebook extracts random points from polygons in the 'polygons_form_naip_images' folder and adds the spectral features at the point extracted from the corresponding NAIP scene. The output is a dataframe of points with the following features:\n",
    "\n",
    "- geometry: coordinates of point *p* in ??? CRS\n",
    "- naip_id: \n",
    "- polygon_id: \n",
    "- iceplant: whether point corresponds to a confirmed iceplant location or a confirmed non-iceplant location (0 = non-iceplant, 1= iceplant)\n",
    "- r, g, b, nir: Red, Green, Blue and NIR bands values of NAIP scene with naip_id at at cooridnates defined by geometry\n",
    "\n",
    "The dataframe is then saved in the 'temp' folder as a csv file.\n",
    "\n",
    "\n",
    "'polygons_form_naip_images'\n",
    "The polygons in confirmed locations as polygons on all available NAIP images over four regions regularly spaced along the Santa Barbara County coast: Carpinteria State Beach, the University of California, Santa Barbara campus, Gaviota State Park, and Point Conception. The polygons outlining confirmed ice plant outgrows are based on field observations and digitized records of ice plant locations from GBIF [*] and Calflora [*].\n",
    "\n",
    "\n",
    "**NOTEBOOK VARIABLES:**\n",
    "\n",
    "- year y from which we will be accessing the CFO California canopy height raster. y must be 2016, 2018 or 2020, since CFO's canopy height data is only available for these years.\n",
    "\n",
    "- file path to which the Santa Barbara County subset of the canopy height data will be saved.\n",
    "\n",
    "**OUTPUT:**\n",
    "\n",
    "- canopy height raster layer for Santa Barbara County in the year y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d21b9a0-c9a8-44fb-9f3f-b07fa5cf2a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "import extracting_points_from_polygons as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537b008-3fab-4251-94ad-177503dab258",
   "metadata": {},
   "source": [
    "# Specify AOI and years from which to sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a1d84e-4b5d-4606-aea2-a14747078dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# ************* NOTEBOOK VARIABLES ******************\n",
    "\n",
    "# aois = ['campus_lagoon','carpinteria','gaviota','point_conception']\n",
    "aoi = 'gaviota'\n",
    "\n",
    "# years = array of years, can be any subset from [2012, 2014, 2016, 2018, 2020]\n",
    "# except if aoi = 'point_conception' (no pts for 2016)\n",
    "years = [2016]\n",
    "\n",
    "\n",
    "# ***************************************************\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b192b4c-5bf5-470d-83e4-bf9b68669536",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pts = []\n",
    "\n",
    "for year in years:\n",
    "    \n",
    "    # open polygons\n",
    "    fp = pp.path_to_polygons(aoi,year)\n",
    "    polys = gpd.read_file(fp)\n",
    "    \n",
    "    polys_ice = polys.loc[polys.iceplant==1]\n",
    "    polys_ice.reset_index(inplace=True, drop=True)\n",
    "    pts_ice = pp.naip_sample_proportion_no_warnings(polys_ice, \n",
    "                                                    polys.naip_id[0], \n",
    "                                                    0.9)  # sample 90% of pts in polygon\n",
    "\n",
    "    print('*** '+str(year)+' # ice plant pts sampled')\n",
    "    print(pts_ice.shape[0])\n",
    "    pts_ice.polygon_id.value_counts()\n",
    "\n",
    "    \n",
    "    polys_nonice = polys.loc[polys.iceplant==0]\n",
    "    polys_nonice.reset_index(inplace=True, drop=True)\n",
    "    pts_nonice = pp.naip_sample_sliding_no_warnings(polys_nonice, polys.naip_id[0], \n",
    "                                                    0.9, # sample 90% of pts in polygon, but at most 1500\n",
    "                                                    1500)\n",
    "\n",
    "    print('*** '+str(year)+' # non ice plant pts sampled')\n",
    "    print(pts_nonice.shape[0])\n",
    "    pts_nonice.polygon_id.value_counts()\n",
    "    \n",
    "    pts = pd.concat([pts_ice,pts_nonice])\n",
    "    print('*** '+str(year)+' # proportions')\n",
    "    pp.iceplant_proportions(pts.iceplant)\n",
    "    \n",
    "    all_pts.append(pts)\n",
    "    \n",
    "    print( '---------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e34b7-9c91-41fc-9e75-c0ea8d513d03",
   "metadata": {},
   "source": [
    "# Save points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c950ba6-30b6-466b-ab19-1b3eccceaf9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(years)):\n",
    "    fp = pp.path_to_points_csv(aoi,years[i])\n",
    "    pts[i].to_csv(fp)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3a2c6-fb1d-415b-bfa2-1bf568172045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
