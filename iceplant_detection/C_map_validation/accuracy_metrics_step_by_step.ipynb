{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "This is a notebook for calculating prducer's accuracies and user's accuracies by class, along with their confidence intervals.\n",
    "We follow the notation and calculations in Olofsson et al. \n",
    "\n",
    "The data input needs to be:\n",
    "1. a csv of the points assessed with two columns: map_class and ref_class. Map class is the classification of the point in the map, ref_class is the \"ground truth\" classification of the point. \n",
    "\n",
    "2. a csv with the number of pixels per class in the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>naip_id</th>\n",
       "      <th>pts_crs</th>\n",
       "      <th>map_class</th>\n",
       "      <th>ref_class</th>\n",
       "      <th>which_raster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-120.465232</td>\n",
       "      <td>34.462486</td>\n",
       "      <td>ca_m_3412037_nw_10_060_20200607</td>\n",
       "      <td>EPSG:4326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-119.997217</td>\n",
       "      <td>34.459656</td>\n",
       "      <td>ca_m_3412040_ne_10_060_20200522</td>\n",
       "      <td>EPSG:4326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-119.969810</td>\n",
       "      <td>34.438493</td>\n",
       "      <td>ca_m_3411933_nw_11_060_20200522</td>\n",
       "      <td>EPSG:4326</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-120.469599</td>\n",
       "      <td>34.465779</td>\n",
       "      <td>ca_m_3412037_nw_10_060_20200607</td>\n",
       "      <td>EPSG:4326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-120.266262</td>\n",
       "      <td>34.471258</td>\n",
       "      <td>ca_m_3412038_ne_10_060_20200522</td>\n",
       "      <td>EPSG:4326</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lon        lat                          naip_id    pts_crs  \\\n",
       "0 -120.465232  34.462486  ca_m_3412037_nw_10_060_20200607  EPSG:4326   \n",
       "1 -119.997217  34.459656  ca_m_3412040_ne_10_060_20200522  EPSG:4326   \n",
       "2 -119.969810  34.438493  ca_m_3411933_nw_11_060_20200522  EPSG:4326   \n",
       "3 -120.469599  34.465779  ca_m_3412037_nw_10_060_20200607  EPSG:4326   \n",
       "4 -120.266262  34.471258  ca_m_3412038_ne_10_060_20200522  EPSG:4326   \n",
       "\n",
       "   map_class  ref_class  which_raster  \n",
       "0          1          1             0  \n",
       "1          1          1             0  \n",
       "2          3          3             2  \n",
       "3          1          1             0  \n",
       "4          2          2             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load validation points\n",
    "df = pd.read_csv('model_AE5FP_validation_pts_map_and_ref_classes.csv')\n",
    "df = df.rename({'AE5FP_class':'map_class'},axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_nonice_2020</th>\n",
       "      <th>n_ice_2020</th>\n",
       "      <th>n_ground_2020</th>\n",
       "      <th>n_water_2020</th>\n",
       "      <th>raster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36271293</td>\n",
       "      <td>5382187</td>\n",
       "      <td>111150412</td>\n",
       "      <td>62968690</td>\n",
       "      <td>modelAE5_FP_2020_merged_crs26910_S_2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1122203</td>\n",
       "      <td>30004</td>\n",
       "      <td>1891593</td>\n",
       "      <td>2893071</td>\n",
       "      <td>modelAE5_FP_2020_merged_crs26910_W_2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89669636</td>\n",
       "      <td>1123921</td>\n",
       "      <td>62587031</td>\n",
       "      <td>69125241</td>\n",
       "      <td>modelAE5_FP_2020_merged_crs26911_2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_nonice_2020  n_ice_2020  n_ground_2020  n_water_2020  \\\n",
       "0       36271293     5382187      111150412      62968690   \n",
       "1        1122203       30004        1891593       2893071   \n",
       "2       89669636     1123921       62587031      69125241   \n",
       "\n",
       "                                    raster  \n",
       "0  modelAE5_FP_2020_merged_crs26910_S_2020  \n",
       "1  modelAE5_FP_2020_merged_crs26910_W_2020  \n",
       "2    modelAE5_FP_2020_merged_crs26911_2020  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load counts of pixels per class in map\n",
    "pix_counts_by_raster = pd.read_csv('model_AE5FP_map_pixel_counts.csv')\n",
    "pix_counts_by_raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([127063132,   6536112, 175629036, 134987002])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pix_counts = pd.DataFrame(data ={'n_other_veg': [sum(pix_counts_by_raster.n_nonice_2020)],\n",
    "                'n_iceplant': [sum(pix_counts_by_raster.n_ice_2020)],\n",
    "                'n_ground': [sum(pix_counts_by_raster.n_ground_2020)],\n",
    "                'n_water': [sum(pix_counts_by_raster.n_water_2020)]})\n",
    "pix_counts = pix_counts.to_numpy()[0]\n",
    "pix_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Here we create a confusion matrix $n$ such that \n",
    "\n",
    "$n_{i,j}$ = number of points predicted as $i$, known to be $j$, \n",
    "\n",
    "which is equivalent to\n",
    "\n",
    "$n_{i,j}$ = number of points that have map class as $i$ and reference class $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points in each reference class\n",
      "(array([0, 1, 2, 3]), array([236, 139, 119, 100])) \n",
      "\n",
      "Points in each map class\n",
      "(array([0, 1, 2, 3]), array([200, 199, 110,  85]))\n"
     ]
    }
   ],
   "source": [
    "# counts by reference class\n",
    "print('Points in each reference class')\n",
    "print(np.unique(df.ref_class, return_counts=True), '\\n')\n",
    "\n",
    "# counts by map class: these should match the counts given by the stratified sample design\n",
    "print('Points in each map class')\n",
    "print(np.unique(df.map_class, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[170,   1,  20,   9],\n",
       "       [ 51, 137,  11,   0],\n",
       "       [ 15,   1,  85,   9],\n",
       "       [  0,   0,   3,  82]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "# using confusion_matrix directly we get a matrix C such that\n",
    "# C_{i,j} = known to be i, predicted as  j \n",
    "# The notation in the paper is \n",
    "# n_{i,j} = predicted as i, known to be j \n",
    "# so we need to take the transpose\n",
    "\n",
    "n = confusion_matrix(df.ref_class, df.map_class, labels=range(0,4)).T\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation\n",
    "Throughout the following, let $p_{ij}$ be the (true) fraction of the map that has map class $i$ and reference class $j$. \n",
    "\n",
    "### User's Accuracy\n",
    "The user's accuracy of class $i$ is the fraction of the area mapped as class $i$ that has reference class $i$, this is (Olofsson et al. eq 2):\n",
    "$$U_i = \\frac{p_{ii}}{p_{i\\cdot}}.$$\n",
    "This is equivalent to the precision of class $i$. For example, when there are two classes (positive and negative) the user's accuracy of the positive class is the same as the precision of the true class (TP/(TP + FP)).\n",
    "\n",
    "To estimate the $U_i$'s from the points sample we have that\n",
    "$$\\hat{U}_i = \\frac{\\hat{p}_{ii}}{\\hat{p}_{i\\cdot}},$$\n",
    "where $\\hat{p}_{ij}$ are the estimations of $p_{ij}$ from the sample. \n",
    "For stratified random sampling in which the sampling strata correspond to the map classes we have that\n",
    "$$\\hat{p}_{ij} = W_i \\frac{n_{ij}}{n_{i\\cdot}},$$\n",
    "where\n",
    "- $W_i$ is the fraction of the map's area classified  as class i,\n",
    "- $n_{ij}$ is number of points with map class $i$, known to be reference class $j$ (entires in the confusion matrix), and\n",
    "- $n_{i\\cdot}$ is the number of points with map class $i$ (row sums in confusion matrix).\n",
    "\n",
    "Notice that the user's accuracy can be simplifeid to\n",
    "$$\\hat{U}_i = \\frac{n_{ii}}{n_{i\\cdot}},$$\n",
    "this is the formula implemented in the code.\n",
    "\n",
    "For user's accuracy of map class $i$, the estiamted variance is (Olfosson et al. eq. 6):\n",
    "$$\\hat{V}(\\hat{U}_i) = \\frac{\\hat{U}_i (1-\\hat{U}_i)}{n_{i\\cdot}-1}.$$\n",
    "\n",
    "**NOTE:** We calculate the user's accuracies first since these are needed to calculate the approximate variance of the overall accuracy. \n",
    "\n",
    "### Variance, Standard Error & Confidence Intervals\n",
    "Recall that the square root of the estimated variance results in the standard error of the estimator. For example, in the case of the estimated overall accuracy of the map $\\hat{O}$ we have that $\\hat{S}(\\hat{O}) = \\sqrt{\\hat{V}(\\hat{O})}$ (see Olofsson et al. eq. 5). \n",
    "\n",
    "Also, the standard error is used to get confidence intervals for the estimated statistic:the 95% confidence interval is estimated as $\\hat{O} \\pm 1.96 \\hat{S}(\\hat{O}) = \\hat{O} \\pm 1.96\\  \\sqrt{\\hat{V}(\\hat{O})}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user's accuracies: [85.0, 68.84422110552764, 77.27272727272727, 96.47058823529412]\n",
      "user's accuracies confidence interval: [4.93586378 6.41807914 7.82723088 3.92593944]\n"
     ]
    }
   ],
   "source": [
    "n_classes = 4\n",
    "\n",
    "# -------------------------------------\n",
    "# points in sample that had class i in map (predicted as i, any true class j)\n",
    "# these will also be used in overal accuracy and producer's accuracies\n",
    "n_idot = [sum(n[i,:]) for i in range(4)]\n",
    "\n",
    "# -------------------------------------\n",
    "# estimated users' accuracy (precision for each class: TP/(TP+FP))\n",
    "U_hat = [n[i,i] / n_idot[i] for i in range(n_classes)]\n",
    "\n",
    "var_U_hat = [U_hat[i] * (1-U_hat[i])/(n_idot[i]-1) for i in range(0,4)]\n",
    "\n",
    "# -------------------------------------\n",
    "print(\"user's accuracies:\", [x*100 for x in U_hat])\n",
    "print(\"user's accuracies confidence interval:\", 1.95*np.sqrt(var_U_hat)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overal Accuracy\n",
    "\n",
    "Let $O$ be the (true) accuracy of the map, and $\\hat{O}$ its estimation from the sample. Then, following Olofsson et al., section 4.3, we have that \n",
    "$$\\hat{O} = \\sum_{i=1}^q \\hat{p}_{ii},$$\n",
    "where $q$ is the number of classes in the map and $\\hat{p}_{ii}$ is the estimation of $p_{ij}$, the (true) fraction of the area in the map that was classified as class $i$ and has reference class $j$. \n",
    "\n",
    "For overall accuracy, the estimated variance is (Olofsson et al. eq 5):\n",
    "$$\\hat{V}(\\hat{O}) = \\sum_{i=1}^q \\frac{W_i^2 \\hat{U}_i (1-\\hat{U}_i)}{n_{i\\cdot}-1}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy: 85.19281389053452\n",
      "overall accuracy confidence interval: 3.605875402993303 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# total number of pixels in the map\n",
    "total_pix = sum(pix_counts)\n",
    "\n",
    "# list with the fractions of area in map mapped as each class\n",
    "W = [pix_counts[i]/ total_pix for i in range(n_classes)]      \n",
    "\n",
    "# -------------------------------------\n",
    "# overall accuracy\n",
    "O_hat = sum([W[i]*n[i,i]/n_idot[i] for i in range(0,4)])\n",
    "print('overall accuracy:', O_hat*100)\n",
    "\n",
    "# -------------------------------------\n",
    "var_O_hat = sum([ W[i]**2 * U_hat[i] * (1-U_hat[i])/(n_idot[i]-1) for i in range(0,4)])\n",
    "\n",
    "# std error of estimated overall accuracy\n",
    "print('overall accuracy confidence interval:', 1.95*np.sqrt(var_O_hat)*100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producer's Accuracy\n",
    "The producer's accuracy of class $i$ is the fraction of the (true) area with reference class $i$ that is actually mapped as class $j$, this is (Olofsson et al. eq 3):\n",
    "$$P_j = \\frac{p_{jj}}{p_{\\cdot j}}.$$\n",
    "This is equivalent to the sensitiviy of class $j$. For example, when there are two classes (positive and negative) the producer's accuracy of the positive class is the same as the sensitivy of the true class (TP/(TP + FN)).\n",
    "\n",
    "To estimate the $P_i$'s from the points sample we have that\n",
    "$$\\hat{P}_j = \\frac{\\hat{p}_{jj}}{\\hat{p}_{\\cdot j}},$$\n",
    "where the $\\hat{p}_{ij}$ are as before.\n",
    "\n",
    "For the producer's accuracy of class $j$ the estimated variance is given by (Olofsson et al. eq 7):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\hat{V}(\\hat{P}_j) = \n",
    "\\frac{1}{\\hat{N}_{\\cdot j}^2} \n",
    "\\left( \n",
    "\\frac{N_{j \\cdot}^2 (1 - \\hat{P}_j)^2 \\hat{U}_j (1-\\hat{U}_j)}{n_{j \\cdot} -1}  \n",
    "+\n",
    "\\hat{P}_j^2\n",
    "\\sum_{i\\neq j}^q \n",
    "\\frac{N_{i\\cdot}^2}{n_{i \\cdot} - 1} \n",
    "\\frac{n_{ij}}{n_{i \\cdot}} \n",
    "\\left( 1 - \\frac{n_{ij}}{n_{i \\cdot}} \\right)\n",
    "\\right),$$\n",
    "where\n",
    "- $N_{j \\cdot}$ is the number of pixels in the map with map class $j$,\n",
    "- $n_{j\\cdot}$ is the number of sample points with map class $j$, and\n",
    "- $\\hat{N}_{\\cdot j} = \\sum_{i=1}^q N_{i\\cdot}\\frac{n_{ij}}{n_{i\\cdot}}$ is the estimated number of pixels with reference class $j$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "producer's accuracies: [80.82402844924152, 66.84417997754406, 88.3865773243483, 86.63598116981504]\n",
      "producer's accuracies confidence interval: [ 6.8722553  33.3373373   4.42737663  5.61087788] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_hat_dotj = []\n",
    "# estimated producer's accurace (sensitiviy for each class TP/(TP+FN))\n",
    "P_hat = []  \n",
    "\n",
    "for j in range(n_classes):\n",
    "    # list of p_hat_ij with fixed j\n",
    "    p_hat_ij = [ W[i]*n[i,j]/n_idot[i] for i in range(n_classes) ]\n",
    "    p_hat_dotj.append(sum(p_hat_ij))  # equation (9)\n",
    "p_hat_dotj\n",
    "\n",
    "\n",
    "P_hat= [ (W[j]*n[j,j]/n_idot[j]) / p_hat_dotj[j] for j in range(n_classes)]\n",
    "# -------------------------------------\n",
    "print(\"producer's accuracies:\", [x*100 for x in P_hat])\n",
    "\n",
    "# -------------------------------------\n",
    "# -------------------------------------\n",
    "# VARIANCE\n",
    "# notice N_jdot is pixel_counts[j]\n",
    "N_hat_cdotj = []\n",
    "for j in range(n_classes):\n",
    "    summands = [ pix_counts[i] * n[i,j]/n_idot[i] for i in range(n_classes)]\n",
    "    N_hat_cdotj.append(sum(summands))\n",
    "\n",
    "# -------------------------------------\n",
    "summand1 = [ (pix_counts[j]**2) * ((1-P_hat[j])**2) * U_hat[j] * (1-U_hat[j]) / (n_idot[j] - 1) \n",
    "            for j in range(n_classes)]\n",
    "\n",
    "# -------------------------------------\n",
    "summand2 = []\n",
    "for j in range(n_classes):\n",
    "    inner = []\n",
    "    for i in range(n_classes):\n",
    "        if i!=j:\n",
    "            inner.append( (pix_counts[i]**2) /(n_idot[i]-1) * (n[i,j])/(n_idot[i]) * ( 1 - n[i,j]/n_idot[i]) ) \n",
    "    summand2.append((P_hat[j]**2) * sum(inner))\n",
    "\n",
    "# -------------------------------------\n",
    "var_P_hat = [1/(N_hat_cdotj[j]**2) *  (summand1[j] + summand2[j]) for j in range(n_classes)]\n",
    "\n",
    "# -------------------------------------\n",
    "# -------------------------------------\n",
    "print(\"producer's accuracies confidence interval:\", 1.95*np.sqrt(var_P_hat)*100, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For stratified random sampling when the map classes are the strata, we have that an estimator of the proportion of area of class $j$ is (Olofsson et al. eq. 9):\n",
    "$$ \\hat{p}_{\\cdot j} = \\sum_{i=1}^q W_i \\frac{n_{ij}}{n_{i\\cdot}}.$$\n",
    "\n",
    "For this estimator of area proportion per class, the standard error is estimated by (Olofsson et al. eq 10):\n",
    "$$S(\\hat{p}_{\\cdot j}) =  \n",
    "\\sqrt{\n",
    "\\sum_{i=1}^q W_i^2 \\frac{ \\frac{n_{ij}}{n_{i\\cdot}} \\left(1 -  \\frac{n_{ij}}{n_{i\\cdot}} \\right)}{n_{i \\cdot}-1}\n",
    "}.$$\n",
    "\n",
    "The estimated area of class $j$ is\n",
    "$$\\hat{A}_j = A \\times \\hat{p}_{\\cdot k},$$\n",
    "where $A$ is the total are of the map. \n",
    "The standard error for the area is given by (Olofsson et al. eq 11):\n",
    "$$ S(\\hat{A}_j) = A \\times S(\\hat{p}_{\\cdot j}).$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of area per class: \n",
      " [30.081846706908088, 1.5154090662249942, 34.565492267897106, 33.8372519589698]\n",
      "confidence interval for percentage area per class:\n",
      " [2.917186667668769, 0.7641169000097102, 3.54075127941016, 2.5010852129609216]\n"
     ]
    }
   ],
   "source": [
    "# PERCENTAGE OF AREA ESTIMATION\n",
    "# we had calculated the are estimators before, they are used in producer's accuracy\n",
    "print(\"percentage of area per class: \\n\", [x*100 for x in p_hat_dotj])\n",
    "\n",
    "# -------------------------------------\n",
    "# STD ERROR\n",
    "SE_p_hat_dotj = []\n",
    "for j in range(n_classes):\n",
    "    summands = [ (W[i]**2) * (n[i,j]/n_idot[i]) * (1 -  (n[i,j]/n_idot[i]))/ (n_idot[i]-1) \n",
    "                for i in range(n_classes)]\n",
    "    SE_p_hat_dotj.append(np.sqrt(sum(summands)))\n",
    "    \n",
    "print(\"confidence interval for percentage area per class:\\n\", [x*1.96*100 for x in SE_p_hat_dotj])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence interval for percentage area per class:\n",
      " [2.917186667668769, 0.7641169000097102, 3.54075127941016, 2.5010852129609216]\n"
     ]
    }
   ],
   "source": [
    "# AREA ESTIMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx area per class (m^2): \n",
      " [33407040.04497487, 1682919.664246231, 38386299.738131836, 37577561.052647054]\n",
      "confidence interval for area per class (m^2):\n",
      " [3239647.2455628067, 848581.0105469481, 3932139.5701876124, 2777550.6829536646]\n"
     ]
    }
   ],
   "source": [
    "map_area = total_pix * 0.25 #in m^2, assuming a resolution of 0.5m per pixel side\n",
    "\n",
    "approx_area_per_class = [map_area * p_hat_dotj[i] for i in range(n_classes)]\n",
    "print(\"approx area per class (m^2): \\n\", approx_area_per_class)\n",
    "\n",
    "SE_area_per_class = [map_area * SE_p_hat_dotj[i] for i in range(n_classes)]\n",
    "print(\"confidence interval for area per class (m^2):\\n\", [x*1.96 for x in SE_area_per_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx area per class (km^2): \n",
      " [3340.704004497487, 168.2919664246231, 3838.6299738131834, 3757.7561052647056]\n",
      "confidence interval for area per class (km^2):\n",
      " [323.96472455628066, 84.85810105469481, 393.2139570187612, 277.75506829536647]\n"
     ]
    }
   ],
   "source": [
    "map_area = total_pix * 0.25 / (100**2)#in km^2, assuming a resolution of 0.5m per pixel side\n",
    "\n",
    "approx_area_per_class = [map_area * p_hat_dotj[i] for i in range(n_classes)]\n",
    "print(\"approx area per class (km^2): \\n\", approx_area_per_class)\n",
    "\n",
    "SE_area_per_class = [map_area * SE_p_hat_dotj[i] for i in range(n_classes)]\n",
    "print(\"confidence interval for area per class (km^2):\\n\", [x*1.96 for x in SE_area_per_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK THESE PAPERS:\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S0034425712004191?casa_token=VRVZgQNuCnoAAAAA:lpifuEHGRTIQIamPd7BaXJVxE5j8LBiyAGX5kTLRz1RCgU_5Uj34g_8lsRKrCz8iGNlYoabJ\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S0034425706004068?casa_token=34fHx5SX2vsAAAAA:_0hDu9LAlVO6JGqeV0yZWmHZ99uW-yoh2QhdTGt4QDr6FZgE9deZQM-xAVH9biVSNJFfc4SV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[170,   1,  20,   9],\n",
       "       [ 51, 137,  11,   0],\n",
       "       [ 15,   1,  85,   9],\n",
       "       [  0,   0,   3,  82]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[680,   4,  80,  36],\n",
       "       [204, 548,  44,   0],\n",
       "       [ 60,   4, 340,  36],\n",
       "       [  0,   0,  12, 328]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=n*2\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user's accuracies: [85.0, 68.84422110552764, 77.27272727272727, 96.47058823529412]\n",
      "user's accuracies confidence interval: [2.46329437 3.20297906 3.90022025 1.95426471]\n",
      "overall accuracy: 85.19281389053452\n",
      "overall accuracy confidence interval: 1.7969960274944623 \n",
      "\n",
      "producer's accuracies: [80.82402844924152, 66.84417997754406, 88.3865773243483, 86.63598116981504]\n",
      "producer's accuracies confidence interval: [ 3.4244642  16.6152207   2.20665601  2.79642297] \n",
      "\n",
      "percentage of area per class: \n",
      " [30.081846706908088, 1.5154090662249942, 34.565492267897106, 33.8372519589698]\n",
      "confidence interval for percentage area per class:\n",
      " [1.4541362047632633, 0.38083924454307405, 1.7644213604024164, 1.2461812512443673]\n",
      "approx area per class (km^2): \n",
      " [3340.704004497487, 168.2919664246231, 3838.6299738131834, 3757.7561052647056]\n",
      "confidence interval for area per class (km^2):\n",
      " [161.4873810663307, 42.29365310284215, 195.94573304449574, 138.39318898615738]\n"
     ]
    }
   ],
   "source": [
    "n_classes = 4\n",
    "\n",
    "# -------------------------------------\n",
    "# points in sample that had class i in map (predicted as i, any true class j)\n",
    "# these will also be used in overal accuracy and producer's accuracies\n",
    "n_idot = [sum(n[i,:]) for i in range(4)]\n",
    "\n",
    "# -------------------------------------\n",
    "#USER'S ACCURACY\n",
    "\n",
    "# estimated users' accuracy (precision for each class: TP/(TP+FP))\n",
    "U_hat = [n[i,i] / n_idot[i] for i in range(n_classes)]\n",
    "\n",
    "var_U_hat = [U_hat[i] * (1-U_hat[i])/(n_idot[i]-1) for i in range(0,4)]\n",
    "\n",
    "# -------------------------------------\n",
    "print(\"user's accuracies:\", [x*100 for x in U_hat])\n",
    "print(\"user's accuracies confidence interval:\", 1.95*np.sqrt(var_U_hat)*100)\n",
    "\n",
    "# -------------------------------------\n",
    "# -------------------------------------\n",
    "\n",
    "# OVERAL ACCURACY\n",
    "# total number of pixels in the map\n",
    "total_pix = sum(pix_counts)\n",
    "\n",
    "# list with the fractions of area in map mapped as each class\n",
    "W = [pix_counts[i]/ total_pix for i in range(n_classes)]      \n",
    "\n",
    "# -------------------------------------\n",
    "# overall accuracy\n",
    "O_hat = sum([W[i]*n[i,i]/n_idot[i] for i in range(0,4)])\n",
    "print('overall accuracy:', O_hat*100)\n",
    "\n",
    "# -------------------------------------\n",
    "var_O_hat = sum([ W[i]**2 * U_hat[i] * (1-U_hat[i])/(n_idot[i]-1) for i in range(0,4)])\n",
    "\n",
    "# std error of estimated overall accuracy\n",
    "print('overall accuracy confidence interval:', 1.95*np.sqrt(var_O_hat)*100, '\\n')\n",
    "# -------------------------------------\n",
    "# -------------------------------------\n",
    "\n",
    "p_hat_dotj = []\n",
    "# estimated producer's accurace (sensitiviy for each class TP/(TP+FN))\n",
    "\n",
    "for j in range(n_classes):\n",
    "    # list of p_hat_ij with fixed j\n",
    "    p_hat_ij = [ W[i]*n[i,j]/n_idot[i] for i in range(n_classes) ]\n",
    "    p_hat_dotj.append(sum(p_hat_ij))  # equation (9)\n",
    "p_hat_dotj\n",
    "\n",
    "\n",
    "P_hat= [ (W[j]*n[j,j]/n_idot[j]) / p_hat_dotj[j] for j in range(n_classes)]\n",
    "# -------------------------------------\n",
    "print(\"producer's accuracies:\", [x*100 for x in P_hat])\n",
    "\n",
    "# -------------------------------------\n",
    "# -------------------------------------\n",
    "# VARIANCE\n",
    "# notice N_jdot is pixel_counts[j]\n",
    "N_hat_cdotj = []\n",
    "for j in range(n_classes):\n",
    "    summands = [ pix_counts[i] * n[i,j]/n_idot[i] for i in range(n_classes)]\n",
    "    N_hat_cdotj.append(sum(summands))\n",
    "\n",
    "# -------------------------------------\n",
    "summand1 = [ (pix_counts[j]**2) * ((1-P_hat[j])**2) * U_hat[j] * (1-U_hat[j]) / (n_idot[j] - 1) \n",
    "            for j in range(n_classes)]\n",
    "\n",
    "# -------------------------------------\n",
    "summand2 = []\n",
    "for j in range(n_classes):\n",
    "    inner = []\n",
    "    for i in range(n_classes):\n",
    "        if i!=j:\n",
    "            inner.append( (pix_counts[i]**2) /(n_idot[i]-1) * (n[i,j])/(n_idot[i]) * ( 1 - n[i,j]/n_idot[i]) ) \n",
    "    summand2.append((P_hat[j]**2) * sum(inner))\n",
    "\n",
    "# -------------------------------------\n",
    "var_P_hat = [1/(N_hat_cdotj[j]**2) *  (summand1[j] + summand2[j]) for j in range(n_classes)]\n",
    "\n",
    "# -------------------------------------\n",
    "# -------------------------------------\n",
    "print(\"producer's accuracies confidence interval:\", 1.95*np.sqrt(var_P_hat)*100, '\\n')\n",
    "\n",
    "\n",
    "# PERCENTAGE OF AREA ESTIMATION\n",
    "# we had calculated the are estimators before, they are used in producer's accuracy\n",
    "print(\"percentage of area per class: \\n\", [x*100 for x in p_hat_dotj])\n",
    "\n",
    "# -------------------------------------\n",
    "# STD ERROR\n",
    "SE_p_hat_dotj = []\n",
    "for j in range(n_classes):\n",
    "    summands = [ (W[i]**2) * (n[i,j]/n_idot[i]) * (1 -  (n[i,j]/n_idot[i]))/ (n_idot[i]-1) \n",
    "                for i in range(n_classes)]\n",
    "    SE_p_hat_dotj.append(np.sqrt(sum(summands)))\n",
    "    \n",
    "print(\"confidence interval for percentage area per class:\\n\", [x*1.96*100 for x in SE_p_hat_dotj])\n",
    "\n",
    "map_area = total_pix * 0.25 / (100**2)#in km^2, assuming a resolution of 0.5m per pixel side\n",
    "\n",
    "approx_area_per_class = [map_area * p_hat_dotj[i] for i in range(n_classes)]\n",
    "print(\"approx area per class (km^2): \\n\", approx_area_per_class)\n",
    "\n",
    "SE_area_per_class = [map_area * SE_p_hat_dotj[i] for i in range(n_classes)]\n",
    "print(\"confidence interval for area per class (km^2):\\n\", [x*1.96 for x in SE_area_per_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "444215282"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "user's accuracies: [85.0, 68.84422110552764, 77.27272727272727, 96.47058823529412]\n",
    "user's accuracies confidence interval: [4.93586378 6.41807914 7.82723088 3.92593944]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
