{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e7dfac-0a24-4575-8459-5f6118ee485f",
   "metadata": {},
   "source": [
    "This notebook can be used to add average and entropy of spectral bands over a window.\n",
    "\n",
    "It **does not** require points to have an associated polygon. \n",
    "\n",
    "it **does** requiere all opints in the csv to have the same crs.\n",
    "\n",
    "It creates a small window around each pont in the NAIP scene and calculates the \"window\" features only in that small region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3132446-b728-4456-bc1f-4ab9faa1602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "import rioxarray as rioxr\n",
    "import rasterio\n",
    "\n",
    "import sample_rasters as sr\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "from shapely.geometry import box\n",
    "\n",
    "import planetary_computer as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea73734-ad00-4dac-9658-0e31c2ee9727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# ************* NOTEBOOK VARIABLES ******************\n",
    "\n",
    "itemids = pd.read_csv(sr.path_to_aoi_itemids_csv())\n",
    "\n",
    "# csv with the points for which to add spectral window features\n",
    "csv_name = 'pepper_dataset.csv'\n",
    "root = '/home/jovyan/msai4earth-esa/iceplant_detection/models/model_pepper/'\n",
    "fp = root + csv_name\n",
    "#fp = os.path.join(os.getcwd(),'temp',csv_name)\n",
    "all_pts = pd.read_csv(fp)\n",
    "\n",
    "# radius of the disk (in pixels) over which entropy is calculated\n",
    "entropy_r = 5\n",
    "\n",
    "# length of side of the square window over which average/max/min are calculated.\n",
    "box_side = entropy_r*2 +1\n",
    "\n",
    "# -------------------------------------------\n",
    "# name of column containing itemid of the NAIP scene containing the point\n",
    "itemid_col = 'naip_id'\n",
    "# name ofcolumns with the crs of all points\n",
    "crs_col = 'pts_crs'\n",
    "\n",
    "save = True\n",
    "\n",
    "# ***************************************************\n",
    "# ***************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15e315-72dc-4f4a-82ac-7373beef8d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMAINING:  5 scenes\r"
     ]
    }
   ],
   "source": [
    "# temporary folder for aux rasters\n",
    "folp = os.path.join(os.getcwd(),'temp','aux_naip_rasters')\n",
    "if os.path.exists(folp) == False:\n",
    "    os.mkdir(folp)\n",
    "    \n",
    "# ===================================================\n",
    "itemids = list(all_pts[itemid_col].unique()) # itemids with points\n",
    "N = len(itemids)  # counter to finish\n",
    "crs = CRS.from_string(all_pts[crs_col][0]) # crs of dataframe\n",
    "\n",
    "# ===================================================\n",
    "sampled_pts = [] # sampled pts from each scene are collected here\n",
    "t0 = time.time() # initial time tracker\n",
    "print('REMAINING: ', N, 'scenes', end=\"\\r\")\n",
    "\n",
    "# ===================================================\n",
    "for i in range(len(itemids)):\n",
    "    # ---------------------------------------\n",
    "    # open raster reader for NAIP scene\n",
    "    itemid = itemids[i]\n",
    "    item = sr.get_item_from_id(itemid)    \n",
    "    href = pc.sign(item.assets[\"image\"].href)\n",
    "    naip_rast_r = rioxr.open_rasterio(href) \n",
    "\n",
    "    pts_scene = all_pts.loc[all_pts['naip_id'] == itemid]\n",
    "\n",
    "    # double check there are points in that scene\n",
    "    if len(pts_scene) !=0:\n",
    "        # create geodataframe with pts in scene\n",
    "        pts_scene_df = sr.geodataframe_from_csv(df = pts_scene, lon_label='x', lat_label='y', crs=crs)\n",
    "        # convert pts to crs of NAIP scene\n",
    "        pts_col = pts_scene_df.to_crs(naip_rast_r.rio.crs).geometry\n",
    "\n",
    "        samples = []\n",
    "        for pt in pts_col:\n",
    "            # this creates a box centered at point with side length=entropy_r*2 meters\n",
    "            #     current pts coordinates are in the NAIP scene's crs, which is in meters\n",
    "            #     entropy_r is in pixels and each pixel has a side of ~0.5m in the NAIP scene\n",
    "            #     so pt.buffer(entropy_r) is a disk with radius entropy_r meters,\n",
    "            #     this disk is inscribed in a square with side length entropy_r*2 meters,\n",
    "            #     which translates into a square of side length entropy_r*4 pixels \n",
    "            #     this square is big enough to have a window of side length entropy_r*2 + 1 pixels \n",
    "            #      around the central pt\n",
    "            reduce_box = box(*(pt.buffer(entropy_r).bounds))            \n",
    "            # clip NAIP scene to box\n",
    "            rast = naip_rast_r.rio.clip_box(*reduce_box.bounds)\n",
    "\n",
    "            # save auxiliary average and entropy rasters for R,G,B,NIR bands of clipped scene\n",
    "            band_names = ['r_', 'g_', 'b_', 'nir_']\n",
    "            tags = ['_maxs','_mins','_avgs', '_entrs']\n",
    "            window_fps = []\n",
    "            window_cols = []\n",
    "\n",
    "            for band_name, band_n in zip(band_names,range(1,5)):\n",
    "                rast_name = band_name + itemid + '_pt'\n",
    "                sr.max_raster(raster = rast, band=band_n, rast_name=rast_name, n=box_side, folder_path=folp)\n",
    "                sr.min_raster(raster = rast, band=band_n, rast_name=rast_name, n=box_side, folder_path=folp)\n",
    "                sr.avg_raster(raster = rast, band=band_n, rast_name=rast_name, n=box_side, folder_path=folp)\n",
    "                sr.entropy_raster(raster = rast, band=band_n, rast_name=rast_name, n=entropy_r, folder_path=folp)                        \n",
    "\n",
    "                for tag in tags:\n",
    "                    window_fps.append(os.path.join(folp, rast_name + tag + '.tif'))        \n",
    "                    window_cols.append(band_name.replace('_','')+tag.replace('s',str(box_side)))\n",
    "\n",
    "            # ------------------------------\n",
    "            # make auxiliary NDVI of clipped scene\n",
    "            ndvi = sr.ndvi_xarray(rast)\n",
    "\n",
    "            # make auxiliary NDVI entropy\n",
    "            band_names.append('ndvi_')\n",
    "            rast_name = 'ndvi_' + itemid + '_pt'\n",
    "            \n",
    "            sr.max_min_avg_rasters(rast_data=ndvi, \n",
    "                              crs=rast.rio.crs, \n",
    "                              transf=rast.rio.transform(), \n",
    "                              rast_name=rast_name, \n",
    "                              n=box_side, \n",
    "                              folder_path=folp)\n",
    "\n",
    "            # adjusting to entropy input types\n",
    "            ndvi = ndvi*100 +100\n",
    "            sr.entropy_raster(rast_data=ndvi.astype('uint8'), \n",
    "                              crs=rast.rio.crs, \n",
    "                              transf=rast.rio.transform(), \n",
    "                              rast_name=rast_name, \n",
    "                              n=entropy_r, \n",
    "                              folder_path=folp)\n",
    "\n",
    "            for tag in tags:\n",
    "                window_fps.append(os.path.join(folp, rast_name + tag + '.tif'))        \n",
    "                window_cols.append( 'ndvi'+tag.replace('s',str(box_side)))\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # sample raster values for points in this scene\n",
    "            pt_samples = []\n",
    "            for fp, col_name in zip(window_fps, window_cols):\n",
    "                rast_r = rasterio.open(fp)\n",
    "                pt_df = gpd.GeoDataFrame({'geometry':[pt]}, crs=pts_col.crs)\n",
    "                sample = sr.sample_raster_from_pts(pt_df.geometry, rast_r, [col_name])    \n",
    "                pt_samples.append(sample)\n",
    "                os.remove(fp)\n",
    "            samples.append(pd.concat(pt_samples, axis=1))\n",
    "            \n",
    "        # ---------------------------------------\n",
    "        # Add all derived spectral data to pts dataframe\n",
    "        new_features = pd.concat(samples)\n",
    "        pts = pd.concat([pts_scene, new_features.set_index(pts_col.index)], axis=1)                \n",
    "\n",
    "        # -----------------------------\n",
    "        # collect all points from each polygon in the scene\n",
    "        sampled_pts.append(pts)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # processing message\n",
    "    N = N-1                \n",
    "    print('REMAINING: ', N, 'scenes', end=\"\\r\")\n",
    "\n",
    "print('FINISHED PROCESSING')       \n",
    "     \n",
    "# ---------------------------------------\n",
    "# create data frame with all points\n",
    "sampled_pts= pd.concat(sampled_pts).sort_index()\n",
    "sampled_pts = sampled_pts.drop(['geometry'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c76c7b-d751-4828-8e51-7404b8e37860",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((time.time() - t0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1b68d6-8758-459c-b850-abb73c9b7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_pts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d434e9-87fd-49e3-8f53-ebab38a93eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    fp = os.path.join(root, 'spectral_window'+str(box_side)+'_'+csv_name)\n",
    "    sampled_pts.to_csv(fp, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6dd271-4330-4c7c-99ee-f2b5d24459eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b8719-4f9b-4a76-8b99-aacc6d0abd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_pts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2a3c0-fe57-4f90-b73a-69e2f2325182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
