{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22271604-a3d1-4887-bb60-b519c6aad648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "import rioxarray as rioxr\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "import dask_gateway\n",
    "import dask.array as da\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "# custom modules\n",
    "import data_sampling_workflow.sample_rasters as sr\n",
    "import raster_to_features as rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b4d53b-63f7-4b97-af24-31cd19704d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **************************************************************\n",
    "# ********* SPECIFY ITEMID AND LIDAR YEAR TO MATCH HERE ********\n",
    "\n",
    "year = 2014\n",
    "\n",
    "scene_ids = pd.read_csv(os.path.join(os.getcwd(),\n",
    "                                     'coastal_scenes_ids',\n",
    "                                     'coastal_scenes_ids_'+str(year)+'.csv')).itemid#.iloc[3:22]\n",
    "scene_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9fc4e9-2c68-4efd-86a9-ba576233ecbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read SB coastal zone shapefile for clipping\n",
    "fp = os.path.join(os.getcwd(),'separating_naip_flights','sb_coast','sb_coast.shp')\n",
    "coast= gpd.read_file(fp)\n",
    "coast_geo = coast.geometry.apply(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b73ca5-94cc-422e-be53-6ab456729f98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# **************************************************************\n",
    "# Create auxiliary canopy height files to sample from\n",
    "\n",
    "lidar_rast_reader = rasterio.open(sr.path_to_lidar(year))   # open canopy height raster\n",
    "rast_name = 'SB_canopy_height_'+str(year) # give a name to canopy height raster\n",
    "\n",
    "# list of file paths to aux canopy height rasters\n",
    "# order of filepaths is: lidar, max, min, avg\n",
    "lidar_fps = [sr.path_to_lidar(year)]  \n",
    "for tag in ['_maxs', '_mins', '_avgs']:\n",
    "    lidar_fps.append(os.path.join(os.getcwd(),\n",
    "                                  'temp',\n",
    "                                  rast_name+tag+'.tif'))\n",
    "\n",
    "if not all([os.path.exists(fp) for fp in lidar_fps]):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # save aux rasters in temp folder\n",
    "    if os.path.exists(fp[1]) == False:\n",
    "        sr.max_raster(rast_reader = lidar_rast_reader, rast_name = rast_name, n=3)\n",
    "\n",
    "    if os.path.exists(fp[2]) == False:\n",
    "        sr.min_raster(rast_reader = lidar_rast_reader, rast_name = rast_name, n=3)  \n",
    "\n",
    "    if os.path.exists(fp[3]) == False:\n",
    "        sr.avg_raster(rast_reader = lidar_rast_reader, rast_name = rast_name, n=3)\n",
    "\n",
    "    print('time to make auxiliary rasters: ', (time.time()-t0), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc750a-74b5-4b34-9a43-6744969ff6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained random forest classifier\n",
    "model_name = 'lidar_spectral_rfc.joblib'\n",
    "rfc = load(model_name) \n",
    "print('loaded model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae5874-c1cc-448f-a600-a221b2faf362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize DASK cluster\n",
    "cluster = dask_gateway.GatewayCluster()\n",
    "client = cluster.get_client()\n",
    "cluster.scale(15)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43562aa-ad1f-4e14-b43a-2f7a26396118",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_0 = time.time()\n",
    "times = []\n",
    "\n",
    "for itemid in scene_ids:\n",
    "    t_alpha = time.time()\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # open NAIP scene and clip to coast\n",
    "    t0 = time.time()\n",
    "    raster = rf.rioxr_from_itemid(itemid).rio.clip(coast_geo, coast.crs)\n",
    "    print('clipped raster', time.time() - t0,' s')\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # select non-zero pixels as df\n",
    "    df = rf.raster_as_df(raster.to_numpy(), ['r','g','b','nir'])\n",
    "    df = df.loc[ (df['nir'] != 0) | (df['r'] != 0) | (df['g'] != 0) | (df['b'] != 0)]\n",
    "    print('selected non-zero pixels')\n",
    "\n",
    "    if df.shape[0] == 0:\n",
    "        print('no data at intersection of scene with coastal buffer')\n",
    "        print('FINISHED: ', itemid , '\\n')\n",
    "\n",
    "    else:\n",
    "        # find vegetation pixels to go into model\n",
    "        # keep ndices of water and low-ndvi pixels\n",
    "        # adds ndvi and ndwi features for each pixel\n",
    "        t0 = time.time()\n",
    "        is_veg, water_index, not_veg_index = rf.add_spectral_features(df, \n",
    "                                                                      ndwi_thresh = 0.3, \n",
    "                                                                      ndvi_thresh = 0.05) \n",
    "        if is_veg.shape[0]==0:\n",
    "            print('no vegetation pixels at intersection of scene data with coastal buffer')\n",
    "            print('FINISHED: ', itemid , '\\n')\n",
    "\n",
    "        else:\n",
    "            # select features\n",
    "            is_veg.drop('ndwi', axis=1, inplace=True)\n",
    "            is_veg = rf.add_date_features(is_veg, rf.rioxr_from_itemid(itemid).datetime)\n",
    "            print('assembled pixels dataframe with features\\n   time taken to assemble: ', time.time() - t0,' s')\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # Resample canopy height layers to match NAIP scene resolution and extent\n",
    "            t0 = time.time()\n",
    "\n",
    "            # resampled canopy height layers as vectors    \n",
    "            lidar_values = []    \n",
    "            for fp in lidar_fps:\n",
    "                match = sr.open_and_match(fp, raster)\n",
    "                match_vector = match.to_numpy().reshape(match.shape[0]*match.shape[1])\n",
    "                lidar_values.append(match_vector)\n",
    "\n",
    "\n",
    "            df_lidar = pd.DataFrame(dict(zip(['lidar', 'max_lidar', 'min_lidar', 'avg_lidar'], lidar_values)))\n",
    "            df_lidar = df_lidar.assign(min_max_diff =  df_lidar['max_lidar'] - df_lidar['min_lidar'])\n",
    "            print('time to resample and reshape rasters: ', (time.time()-t0), 'seconds')\n",
    "\n",
    "            # ****************** add LIDAR features to vegetation dataframe *************************\n",
    "\n",
    "            scene_features = pd.concat([is_veg, df_lidar.iloc[is_veg.index]], axis=1)\n",
    "\n",
    "            # reorder columns to match classifier feature order\n",
    "            feature_order = ['r', 'g', 'b', 'nir', 'ndvi', \n",
    "                              'year', 'month', 'day_in_year',\n",
    "                              'lidar', 'max_lidar', 'min_lidar', 'min_max_diff', 'avg_lidar']\n",
    "\n",
    "            scene_features = scene_features[feature_order]\n",
    "\n",
    "            # ---------------------------------------\n",
    "            #free memory\n",
    "            del is_veg, df_lidar, match_vector, lidar_values\n",
    "            gc.collect()\n",
    "\n",
    "            # ****************** PREDICT USING DASK *****************************\n",
    "            # convert into dask.array and predict using model\n",
    "            da_pixels = da.from_array(np.array(scene_features), chunks=728802)\n",
    "            scene_preds = rfc.predict(da_pixels)\n",
    "            t0 = time.time()\n",
    "            preds = scene_preds.compute()\n",
    "            print('time taken to predict: ', time.time() - t0,' s')\n",
    "\n",
    "\n",
    "            # ****************** RECONSTRUCT INTO IMAGE *************************\n",
    "            # recover pixel indices for iceplant classifications\n",
    "            preds_df = pd.DataFrame(preds, \n",
    "                                 columns=['is_iceplant'], \n",
    "                                 index = scene_features.index)\n",
    "            is_iceplant_index = preds_df[preds_df.is_iceplant == 1].index.to_numpy()\n",
    "            non_iceplant_index = preds_df[preds_df.is_iceplant == 0].index.to_numpy()\n",
    "\n",
    "\n",
    "            # indices of different categories\n",
    "            indices = [non_iceplant_index,\n",
    "                       is_iceplant_index, \n",
    "                       not_veg_index,\n",
    "                       water_index]\n",
    "            values = [0,    # values assigned to pixels from each index\n",
    "                      1,\n",
    "                      2,\n",
    "                      3]\n",
    "            t0 = time.time()\n",
    "            reconstruct = rf.indices_to_image(raster.shape[1], raster.shape[2], indices, values, back_value=100)\n",
    "            print('reconstructed image\\n   time taken to reconstruct: ', time.time() - t0,' s')\n",
    "\n",
    "\n",
    "            # ****************** APPLY 3x3 MEDIAN FILTER *************************\n",
    "            if filter:\n",
    "                t0 = time.time()\n",
    "                reconstruct = median_filter(reconstruct, size=3)\n",
    "                print('time taken to filter: ', time.time()- t0,' s')\n",
    "\n",
    "            # ****************** SAVE PREDICTIONS AS RASTER *********************\n",
    "            filename = 'LS_clip_filter_preds_' + itemid + '.tif'\n",
    "            with rasterio.open(\n",
    "                os.path.join(os.getcwd(), 'temp', filename),  # file path\n",
    "                'w',           # w = write\n",
    "                driver = 'GTiff', # format\n",
    "                height = reconstruct.shape[0], \n",
    "                width = reconstruct.shape[1],\n",
    "                count = 1,  # number of raster bands in the dataset\n",
    "                dtype = rasterio.uint8,\n",
    "                crs = raster.rio.crs,\n",
    "                transform = raster.rio.transform(),\n",
    "            ) as dst:\n",
    "                dst.write(reconstruct.astype(rasterio.uint8), 1)\n",
    "            print('saved predictions')\n",
    "\n",
    "            # ****************** RECORD TOTAL TIME *********************\n",
    "            total =  time.time() - t_alpha\n",
    "            times.append(total)\n",
    "            print('total time:', total)\n",
    "            print('FINISHED: ', itemid , '\\n')\n",
    "            \n",
    "print(time.time() - total_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1ba25-7b05-49eb-81ac-74be25e22cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(1,4):   # delete aux canopy height rasters\n",
    "for i in range(1,4):\n",
    "    os.remove(lidar_fps[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414704c-f4a3-4d45-8d52-3d7e1a024eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815b6e44-0725-45c2-8b61-230c83e92e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
