{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22271604-a3d1-4887-bb60-b519c6aad648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc   # garbage collector\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import rasterio\n",
    "\n",
    "import dask_gateway\n",
    "import dask.array as da\n",
    "\n",
    "from joblib import load\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "# custom modules\n",
    "import raster_to_features as rf\n",
    "import data_sampling_workflow.sample_rasters as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9190925a-4975-4545-bad8-78498a2e8c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year for which to predict iceplant locations\n",
    "year = 2020\n",
    "\n",
    "# whether to apply median filter to raster\n",
    "filter_rasters = True\n",
    "\n",
    "# whether to save rasters\n",
    "save_rasters = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38b73ca5-94cc-422e-be53-6ab456729f98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to make auxiliary rasters:  22.281490564346313 seconds\n"
     ]
    }
   ],
   "source": [
    "# **************************************************************\n",
    "# Create auxiliary canopy height files to sample from\n",
    "\n",
    "# open canopy height raster for given year\n",
    "lidar_rast_reader = rasterio.open(sr.path_to_lidar(year))   \n",
    "# name of output canopy height raster\n",
    "rast_name = 'SB_canopy_height_' + str(year) \n",
    "\n",
    "# list of file paths to aux canopy height rasters\n",
    "# order of filepaths is: lidar, max, min, avg\n",
    "lidar_fps = [sr.path_to_lidar(year)]  \n",
    "for tag in ['_maxs', '_mins', '_avgs']:\n",
    "    lidar_fps.append(os.path.join(os.getcwd(),\n",
    "                                  'temp',\n",
    "                                  rast_name + tag + '.tif'))\n",
    "\n",
    "# create any missing aux raster\n",
    "if not all([os.path.exists(fp) for fp in lidar_fps]):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # save aux rasters in temp folder\n",
    "    if os.path.exists(lidar_fps[1]) == False:  # starts at 1 bc 0 is canopy height raster\n",
    "        sr.max_raster(rast_reader = lidar_rast_reader, rast_name = rast_name, n=3)\n",
    "\n",
    "    if os.path.exists(lidar_fps[2]) == False:\n",
    "        sr.min_raster(rast_reader = lidar_rast_reader, rast_name = rast_name, n=3)  \n",
    "\n",
    "    if os.path.exists(lidar_fps[3]) == False:\n",
    "        sr.avg_raster(rast_reader = lidar_rast_reader, rast_name = rast_name, n=3)\n",
    "\n",
    "    print('time to make auxiliary rasters: ', (time.time() - t0), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c38d1e4-9802-468c-86b9-6fd98b20bd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     ca_m_3412037_nw_10_060_20200607\n",
       "1     ca_m_3412037_ne_10_060_20200607\n",
       "2     ca_m_3412029_sw_10_060_20200607\n",
       "3     ca_m_3412004_sw_10_060_20200607\n",
       "4     ca_m_3412003_se_10_060_20200607\n",
       "5     ca_m_3412003_ne_10_060_20200607\n",
       "6     ca_m_3412038_nw_10_060_20200523\n",
       "7     ca_m_3412040_nw_10_060_20200522\n",
       "8     ca_m_3412040_ne_10_060_20200522\n",
       "9     ca_m_3412039_nw_10_060_20200522\n",
       "10    ca_m_3412039_ne_10_060_20200522\n",
       "11    ca_m_3412038_ne_10_060_20200522\n",
       "12    ca_m_3411933_nw_11_060_20200522\n",
       "13    ca_m_3411933_ne_11_060_20200522\n",
       "14    ca_m_3411945_nw_11_060_20200521\n",
       "15    ca_m_3411937_sw_11_060_20200521\n",
       "16    ca_m_3411936_sw_11_060_20200521\n",
       "17    ca_m_3411936_se_11_060_20200521\n",
       "18    ca_m_3411935_sw_11_060_20200521\n",
       "19    ca_m_3411935_se_11_060_20200521\n",
       "20    ca_m_3411934_sw_11_060_20200521\n",
       "21    ca_m_3411934_se_11_060_20200521\n",
       "22    ca_m_3411933_sw_11_060_20200521\n",
       "23    ca_m_3411933_se_11_060_20200521\n",
       "Name: itemid, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# open shapefile of SB coastal buffer and process it to use it for clipping\n",
    "fp = os.path.join(os.getcwd(), \n",
    "                  'separating_naip_flights', \n",
    "                  'SB_coastal_buffer', \n",
    "                  'SB_coastal_buffer.shp')\n",
    "coast = gpd.read_file(fp)\n",
    "coast_geo = coast.geometry.apply(mapping)\n",
    "\n",
    "# ---------------------------------------\n",
    "# load pre-trained random forest classifier\n",
    "rfc = load('lidar_spectral_rfc.joblib') \n",
    "print('loaded model')\n",
    "\n",
    "# ---------------------------------------\n",
    "# select the scene ids from given year that intersect the coastal buffer\n",
    "# the itemids of all scenes that intersect the coast were previously stored in a csv\n",
    "scene_ids = pd.read_csv(os.path.join(os.getcwd(),\n",
    "                                     'separating_naip_flights',\n",
    "                                     'coastal_scenes_ids.csv'))\n",
    "scene_ids = scene_ids.loc[scene_ids['year'] == year]\n",
    "scene_ids = scene_ids.reset_index().itemid\n",
    "scene_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ae5874-c1cc-448f-a600-a221b2faf362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-2705af36-5712-11ed-8533-3aa04a0afa76</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_gateway.GatewayCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.7c1f0223375349e59a52a37f3edd0c83/status\" target=\"_blank\">https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.7c1f0223375349e59a52a37f3edd0c83/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div style='background-color: #f2f2f2; display: inline-block; padding: 10px; border: 1px solid #999999;'>\n",
       "  <h3>GatewayCluster</h3>\n",
       "  <ul>\n",
       "    <li><b>Name: </b>prod.7c1f0223375349e59a52a37f3edd0c83\n",
       "    <li><b>Dashboard: </b><a href='https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.7c1f0223375349e59a52a37f3edd0c83/status' target='_blank'>https://pccompute.westeurope.cloudapp.azure.com/compute/services/dask-gateway/clusters/prod.7c1f0223375349e59a52a37f3edd0c83/status</a>\n",
       "  </ul>\n",
       "</div>\n",
       "\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://10.244.65.54:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize DASK cluster\n",
    "cluster = dask_gateway.GatewayCluster()\n",
    "cluster.scale(15)\n",
    "\n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5a04c9-8342-4c73-9c82-85bc3b4ab348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 85.81719446182251\n",
      "FINISHED:  ca_m_3412037_nw_10_060_20200607\n",
      "REMAINING:  23 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 49.578001499176025\n",
      "FINISHED:  ca_m_3412037_ne_10_060_20200607\n",
      "REMAINING:  22 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 30.285654306411743\n",
      "FINISHED:  ca_m_3412029_sw_10_060_20200607\n",
      "REMAINING:  21 scenes \n",
      "\n",
      "no data at intersection of scene with coastal buffer\n",
      "FINISHED:  ca_m_3412004_sw_10_060_20200607 \n",
      "\n",
      "no vegetation pixels at intersection of scene data with coastal buffer\n",
      "FINISHED:  ca_m_3412003_se_10_060_20200607 \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 37.09280824661255\n",
      "FINISHED:  ca_m_3412003_ne_10_060_20200607\n",
      "REMAINING:  18 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 48.50507354736328\n",
      "FINISHED:  ca_m_3412038_nw_10_060_20200523\n",
      "REMAINING:  17 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 50.09053921699524\n",
      "FINISHED:  ca_m_3412040_nw_10_060_20200522\n",
      "REMAINING:  16 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 53.85923147201538\n",
      "FINISHED:  ca_m_3412040_ne_10_060_20200522\n",
      "REMAINING:  15 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 48.760125160217285\n",
      "FINISHED:  ca_m_3412039_nw_10_060_20200522\n",
      "REMAINING:  14 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 51.40849685668945\n",
      "FINISHED:  ca_m_3412039_ne_10_060_20200522\n",
      "REMAINING:  13 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 47.175222873687744\n",
      "FINISHED:  ca_m_3412038_ne_10_060_20200522\n",
      "REMAINING:  12 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 67.08548426628113\n",
      "FINISHED:  ca_m_3411933_nw_11_060_20200522\n",
      "REMAINING:  11 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 36.033801317214966\n",
      "FINISHED:  ca_m_3411933_ne_11_060_20200522\n",
      "REMAINING:  10 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 24.100707530975342\n",
      "FINISHED:  ca_m_3411945_nw_11_060_20200521\n",
      "REMAINING:  9 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 46.63280177116394\n",
      "FINISHED:  ca_m_3411937_sw_11_060_20200521\n",
      "REMAINING:  8 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 68.56146287918091\n",
      "FINISHED:  ca_m_3411936_sw_11_060_20200521\n",
      "REMAINING:  7 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 67.13203287124634\n",
      "FINISHED:  ca_m_3411936_se_11_060_20200521\n",
      "REMAINING:  6 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 62.84481453895569\n",
      "FINISHED:  ca_m_3411935_sw_11_060_20200521\n",
      "REMAINING:  5 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 56.37400722503662\n",
      "FINISHED:  ca_m_3411935_se_11_060_20200521\n",
      "REMAINING:  4 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 59.16711950302124\n",
      "FINISHED:  ca_m_3411934_sw_11_060_20200521\n",
      "REMAINING:  3 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 72.42515754699707\n",
      "FINISHED:  ca_m_3411934_se_11_060_20200521\n",
      "REMAINING:  2 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 36.4633047580719\n",
      "FINISHED:  ca_m_3411933_sw_11_060_20200521\n",
      "REMAINING:  1 scenes \n",
      "\n",
      "finished pre-processing\n",
      "finished classification\n",
      "finished post-processing\n",
      "total time: 72.94305205345154\n",
      "FINISHED:  ca_m_3411933_se_11_060_20200521\n",
      "REMAINING:  0 scenes \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# collect processing information for each scene\n",
    "times_pre = []\n",
    "times_class = []\n",
    "times_post = []\n",
    "processed = []\n",
    "reason = []\n",
    "n_pixels = []\n",
    "\n",
    "# counter for scenes queued for processing\n",
    "N = len(scene_ids)\n",
    "\n",
    "# ---------------------------------------\n",
    "# prepare folder to save rasters\n",
    "if save_rasters:\n",
    "    fp = os.path.join(os.getcwd(),'temp')\n",
    "    if os.path.exists(fp) == False:\n",
    "        os.mkdir(fp)\n",
    "    if filter_rasters:\n",
    "        fp = os.path.join(fp, 'LS_filter_clip_preds_' + str(year))\n",
    "    else:\n",
    "        fp = os.path.join(fp, 'temp', 'LS_clip_preds_' + str(year))\n",
    "    if os.path.exists(fp) == False:\n",
    "        os.mkdir(fp)\n",
    "\n",
    "# ---------------------------------------\n",
    "# ---------------------------------------\n",
    "\n",
    "for itemid in scene_ids:\n",
    "    t_alpha = time.time()\n",
    "    \n",
    "    # ***********************************************************************************************\n",
    "    # *************************************** PRE-PROCESSING ****************************************\n",
    "    # open NAIP scene and clip to coast\n",
    "    t0 = time.time()\n",
    "    raster = rf.rioxr_from_itemid(itemid).rio.clip(coast_geo, coast.crs)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # select pixels with data (blacked out portions have 0 on all bands)\n",
    "    df = rf.raster_as_df(raster.to_numpy(), ['r','g','b','nir'])\n",
    "    df = df.loc[ (df['nir'] != 0) | (df['r'] != 0) | (df['g'] != 0) | (df['b'] != 0)]\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # stop if there's no data at intersection\n",
    "    if df.shape[0] == 0:\n",
    "        processed.append('N')\n",
    "        reason.append('no data in intersection')\n",
    "        times_pre.append(0)\n",
    "        times_class.append(0)        \n",
    "        times_post.append(0)\n",
    "        n_pixels.append(0)\n",
    "        N = N-1\n",
    "        print('no data at intersection of scene with coastal buffer')\n",
    "        print('FINISHED: ', itemid , '\\n')\n",
    "\n",
    "    else:\n",
    "        # find vegetation pixels to go into model\n",
    "        # keep ndices of water and low-ndvi pixels\n",
    "        # add ndvi and ndwi features for each pixel\n",
    "        t0 = time.time()\n",
    "        is_veg, water_index, not_veg_index = rf.add_spectral_features(df, \n",
    "                                                                      ndwi_thresh = 0.3, \n",
    "                                                                      ndvi_thresh = 0.05) \n",
    "      # ---------------------------------------\n",
    "        # stop if there are no vegetation pixels at intersection\n",
    "        if is_veg.shape[0] == 0:\n",
    "            processed.append('N')\n",
    "            reason.append('no vegeatation in intersection')\n",
    "            times_pre.append(0)\n",
    "            times_class.append(0)        \n",
    "            times_post.append(0)\n",
    "            n_pixels.append(0)\n",
    "            N = N-1\n",
    "            print('no vegetation pixels at intersection of scene data with coastal buffer')\n",
    "            print('FINISHED: ', itemid , '\\n')\n",
    "\n",
    "        else:\n",
    "            processed.append('Y')\n",
    "            reason.append('processed')  \n",
    "            \n",
    "            # ---------------------------------------\n",
    "            # discard ndwi and add date features\n",
    "            is_veg.drop('ndwi', axis=1, inplace=True)\n",
    "            is_veg = rf.add_date_features(is_veg, rf.rioxr_from_itemid(itemid).datetime)\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # Resample canopy height layers to match NAIP scene resolution and extent\n",
    "\n",
    "            # resampled canopy height layers as vectors    \n",
    "            lidar_values = []    \n",
    "            for fp_aux in lidar_fps:\n",
    "                match = sr.open_and_match(fp_aux, raster)\n",
    "                match_vector = match.to_numpy().reshape(match.shape[0]*match.shape[1])\n",
    "                lidar_values.append(match_vector)\n",
    "\n",
    "            df_lidar = pd.DataFrame(dict(zip(['lidar', 'max_lidar', 'min_lidar', 'avg_lidar'], lidar_values)))\n",
    "            df_lidar = df_lidar.assign(min_max_diff =  df_lidar['max_lidar'] - df_lidar['min_lidar'])\n",
    "\n",
    "            # ---------------------------------------\n",
    "            #  add canopy height features to vegetation dataframe \n",
    "            scene_features = pd.concat([is_veg, df_lidar.iloc[is_veg.index]], axis=1)\n",
    "\n",
    "            # reorder columns to match classifier feature order\n",
    "            feature_order = ['r', 'g', 'b', 'nir', 'ndvi', \n",
    "                              'year', 'month', 'day_in_year',\n",
    "                              'lidar', 'max_lidar', 'min_lidar', 'min_max_diff', 'avg_lidar']\n",
    "\n",
    "            scene_features = scene_features[feature_order]\n",
    "            \n",
    "            # ---------------------------------------\n",
    "            times_pre.append(time.time() - t0)\n",
    "            n_pixels.append(len(is_veg))       \n",
    "            print('finished pre-processing')\n",
    "\n",
    "            # ---------------------------------------\n",
    "            #free memory\n",
    "            del is_veg, df_lidar, match_vector, lidar_values\n",
    "            gc.collect()\n",
    "\n",
    "    # ***********************************************************************************************\n",
    "    # *************************************** CLASSIFICATION ****************************************\n",
    "            # convert into dask.array and predict using model\n",
    "            da_pixels = da.from_array(np.array(scene_features), chunks=728802)\n",
    "            scene_preds = rfc.predict(da_pixels)\n",
    "            \n",
    "            # ---------------------------------------\n",
    "            t0 = time.time()\n",
    "            preds = scene_preds.compute()\n",
    "            times_class.append(time.time() - t0)\n",
    "            print('finished classification')\n",
    "\n",
    "    # ************************************************************************************************\n",
    "    # *************************************** POST-PROCESSING ****************************************\n",
    "            # recover pixel indices for iceplant classifications\n",
    "            t0 = time.time()\n",
    "            preds_df = pd.DataFrame(preds, \n",
    "                                 columns=['is_iceplant'], \n",
    "                                 index = scene_features.index)\n",
    "            is_iceplant_index = preds_df[preds_df.is_iceplant == 1].index.to_numpy()\n",
    "            non_iceplant_index = preds_df[preds_df.is_iceplant == 0].index.to_numpy()\n",
    "\n",
    "            # ---------------------------------------\n",
    "            # reconstruct indices into image\n",
    "            indices = [non_iceplant_index,\n",
    "                       is_iceplant_index, \n",
    "                       not_veg_index,\n",
    "                       water_index]\n",
    "            values = [0,    # values assigned to pixels from each index\n",
    "                      1,\n",
    "                      2,\n",
    "                      3]\n",
    "            reconstruct = rf.indices_to_image(raster.shape[1], raster.shape[2], indices, values, back_value=100)\n",
    "            \n",
    "            # ---------------------------------------\n",
    "            # apply median 3x3 filter if needed\n",
    "            if filter:\n",
    "                reconstruct = median_filter(reconstruct, size=3)\n",
    "            \n",
    "            times_post.append(time.time() - t0)\n",
    "            print('finished post-processing')\n",
    "\n",
    "    # ************************************************************************************************\n",
    "    # *************************************** SAVE RASTERS *******************************************  \n",
    "            if save_rasters:\n",
    "                if filter_rasters:\n",
    "                    filename = 'LS_filter_clip_preds_' + itemid + '.tif'\n",
    "                else:\n",
    "                    filename = 'LS_clip_preds_' + itemid + '.tif'\n",
    "                \n",
    "                with rasterio.open(\n",
    "                    os.path.join(fp, filename),  # file path\n",
    "                    'w',           # w = write\n",
    "                    driver = 'GTiff', # format\n",
    "                    height = reconstruct.shape[0], \n",
    "                    width = reconstruct.shape[1],\n",
    "                    count = 1,  # number of raster bands in the dataset\n",
    "                    dtype = rasterio.uint8,\n",
    "                    crs = raster.rio.crs,\n",
    "                    transform = raster.rio.transform(),\n",
    "                ) as dst:\n",
    "                    dst.write(reconstruct.astype(rasterio.uint8), 1)\n",
    "                \n",
    "    # ************************************************************************************************\n",
    "    # ************************************ FINAL INFO MESSAGE ***************************************            \n",
    "            N = N-1\n",
    "            print('total time:', time.time() - t_alpha)\n",
    "            print('FINISHED: ', itemid)\n",
    "            print('REMAINING: ', N, 'scenes \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815b6e44-0725-45c2-8b61-230c83e92e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save times processed and itemids as dataframe\n",
    "D = { 'itemid': scene_ids,\n",
    "     'processed': processed,\n",
    "     'reason':reason,\n",
    "     'pre_times': times_pre,\n",
    "     'class_times' : times_class,\n",
    "     'post_times' : times_post, \n",
    "     'n_pixels' : n_pixels}\n",
    "processing_df = pd.DataFrame( D )\n",
    "\n",
    "fp = os.path.join(os.getcwd(),'processing_results')\n",
    "if os.path.exists(fp) == False:\n",
    "    os.mkdir(fp)\n",
    "\n",
    "    \n",
    "if filter_rasters:\n",
    "    filename = 'LS_filter_clip_processing_results_' + str(year) + '.csv'\n",
    "else:\n",
    "    filename = 'LS_clip_processing_results_' + str(year) + '.csv'\n",
    "    \n",
    "processing_df.to_csv(os.path.join(fp, filename ), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0c1ba25-7b05-49eb-81ac-74be25e22cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 23:25:23,236 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n",
      "Exception in callback None()\n",
      "handle: <Handle cancelled>\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1391, in _do_ssl_handshake\n",
      "    self.socket.do_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/ssl.py\", line 1342, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "ssl.SSLEOFError: EOF occurred in violation of protocol (_ssl.c:997)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 696, in _handle_events\n",
      "    self._handle_read()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1478, in _handle_read\n",
      "    self._do_ssl_handshake()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 1400, in _do_ssl_handshake\n",
      "    return self.close(exc_info=err)\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 611, in close\n",
      "    self._signal_closed()\n",
      "  File \"/srv/conda/envs/notebook/lib/python3.10/site-packages/tornado/iostream.py\", line 641, in _signal_closed\n",
      "    self._ssl_connect_future.exception()\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "#for i in range(1,4):   # delete aux canopy height rasters\n",
    "for i in range(1,4):\n",
    "    os.remove(lidar_fps[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be49ee09-d553-4f54-8ac3-92c76153aca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
